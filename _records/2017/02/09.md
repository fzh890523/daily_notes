

# 内核代码里是否用到信号量之类的东西



## 引子

JS:
请教下:
JS:
   信号量不允许使用在中断中怎么理解啊？ 
w@eleme:
因为中断上下文内，处理过程是不能睡眠或者放弃CPU的，而信号量可能会因为抢不到信号量而导致当前程序睡眠。所以信号量不能用在中断内。

JS:
@w@饿了么  谢谢  中断上下文  已经到内核空间了吧   内核空间一般开发人员是用不到信号量了吧。
我:
嗯，我也纳闷的是，ISR在内核空间，有信号量可以用吗？

我:
大佬大佬。 刚才的问题，我记得不太清楚了。 帮忙解答一下。
1\. 内核代码有信号量之类的东西可以用吗
2\. “因为中断上下文内，处理过程是不能睡眠或者放弃CPU的”这个的原因是什么？
   :
1\. 因为中断都在内核态，所以本来就不能用，以至于干脆就没做。 2. 因为硬件要求。。。
   我:
   嗯第一个我也是这么理解的，但又搜到内核态信号量的说法，我再确认一下。
   第二个的话，硬件自然要求ISR尽快处理完，但如果真的睡眠或者放弃CPU的话又会怎么样呢？ 这个“要求”没法强制吧。
   :
   第一个，内核里确实有 sema_init 这个函数，但是。。。
   :
   我忘了。。。
   我:
   逻辑上来说，内核代码的执行路径之间也应该有资源保护等需求。 但ISR只要把状态反馈就够了所以一般不会。 这里等于是两个问题。
   :
   第二个，ISR是打断执行的你造不，一旦放弃CPU，却不能释放处理栈，则系统无法再对这个线程进行调度，会导致某种意义上的 循环等待。
   :
   也就是死锁的普遍形式。。。
   我:
   嗯。有点印象，但是忘球了。 我再去看看书。 
   我:
   羡慕学的扎实的大佬。



## semaphore实现

ref:

*  [How are semaphores implemented in the Linux kernel?](https://www.quora.com/How-are-semaphores-implemented-in-the-Linux-kernel)

   ```c
   /*
   * trylock for reading -- returns 1 if successful, 0 if contention
   */
   int down_read_trylock(struct rw_semaphore *sem)
   {
          int ret = __down_read_trylock(sem);
          if (ret == 1) {
                  rwsem_acquire_read(&sem->dep_map, 0, 1, _RET_IP_);
                  rwsem_set_reader_owned(sem);
          }
          return ret;
   }

     // ...

     static inline bool __down_read_trylock(struct rw_semaphore *sem)
     {
             long result, tmp;
             asm volatile("# beginning __down_read_trylock\n\t"
                          "  mov          %0,%1\n\t"
                          "1:\n\t"
                          "  mov          %1,%2\n\t"
                          "  add          %3,%2\n\t"
                          "  jle          2f\n\t"
                          LOCK_PREFIX "  cmpxchg  %2,%0\n\t"
                          "  jnz          1b\n\t"
                          "2:\n\t"
                          "# ending __down_read_trylock\n\t"
                          : "+m" (sem->count), "=&a" (result), "=&r" (tmp)
                          : "i" (RWSEM_ACTIVE_READ_BIAS)
                          : "memory", "cc");
             return result >= 0;
     }

     // ...

     /*
   *  If there are no writers and no waiting writers, down_read()
   *  acquires the rwsem
           */
          static inline void down_read(struct rw_semaphore *sem)
          {
             spin_lock(&sem->lock);
             dump_rwsem(__FUNCTION__ " in", sem);
             if (sem->nr_holders < 0 || waitqueue_active(&sem->writers_wait))
                 down_read_wait(sem);
             sem->nr_holders++;
             dump_rwsem(__FUNCTION__ " out", sem);
             spin_unlock(&sem->lock);
          }
          
          // ...
          
          /*
      * down_read() failed to acquire the rwsem.  We sleep
      * until there are no writers holding it and no writers
      * requesting it.
        */
        void down_read_wait(struct rw_semaphore *sem)
        {
        struct task_struct *tsk = current;
        DECLARE_WAITQUEUE(wait, tsk);
        dump_rwsem(__FUNCTION__ " in", sem);
        __add_wait_queue(&sem->readers_wait, &wait);
        do {
            __set_task_state(tsk, TASK_UNINTERRUPTIBLE);
            spin_unlock(&sem->lock);
            schedule();
            spin_lock(&sem->lock);
        } while (sem->nr_holders < 0 || waitqueue_active(&sem->writers_wait));
        __remove_wait_queue(&sem->readers_wait, &wait);
        dump_rwsem(__FUNCTION__ " out", sem);
        }
        EXPORT_SYMBOL_NOVERS(down_read_wait);
   ```


* [信号量学习笔记](http://blog.csdn.net/yongan1006/article/details/6682418) or [local](resource/信号量学习笔记 - yongan1006的专栏 - 博客频道 - CSDN.NET.html)
* [linux 内核信号量 用户态信号量 详解](http://blog.csdn.net/weed_hz/article/details/8965733) or [local](resource/linux 内核信号量 用户态信号量 详解 - weed_hz的专栏 - 博客频道 - CSDN.NET.htm)
* [Linux 内核信号量与用户态信号量（System V&POSIX）总结](http://www.360doc.com/content/12/0723/00/9298584_225900606.shtml) or [local](resource/Linux 内核信号量与用户态信号量（System V&POSIX）总结.htm)




## 内核semaphore vs 用户态（glibc）semaphore

* 内核semaphore
  * 给内核和驱动程序使用，而***不是glibc semaphore的内核实现***
  * 看代码（如前面ref里的）是单独实现（内核空间就无所谓syscall之类了）
* glibc semaphore
  * 给应用程序使用
  * 看glibc代码是基于`atomic+futex`



## 内核semaphore



### 介绍



**数据结构**

```c
struct semaphore {
　　 atomic_t count;
　　 int sleepers;
　　 wait_queue_head_t wait;
　　}
```

**内核信号量的相关函数**

初始化：

```c
void sema_init (struct semaphore *sem, int val);
void init_MUTEX (struct semaphore *sem); //将sem的值置为1，表示资源空闲
void init_MUTEX_LOCKED (struct semaphore *sem); //将sem的值置为0，表示资源忙
```

**申请内核信号量所保护的资源：**

```c
void down(struct semaphore * sem); // 可引起睡眠
int down_interruptible(struct semaphore * sem); // down_interruptible能被信号打断
int down_trylock(struct semaphore * sem); // 非阻塞函数，不会睡眠。无法锁定资源则马上返回
```

**释放内核信号量所保护的资源：**

```c
void up(struct semaphore * sem);
```



### source code

实现见上面的...。

```c
/*
 * Copyright (c) 2008 Intel Corporation
 * Author: Matthew Wilcox <willy@linux.intel.com>
 *
 * Distributed under the terms of the GNU GPL, version 2
 *
 * This file implements counting semaphores.
 * A counting semaphore may be acquired 'n' times before sleeping.
 * See mutex.c for single-acquisition sleeping locks which enforce
 * rules which allow code to be debugged more easily.
 */

/*
 * Some notes on the implementation:
 *
 * The spinlock controls access to the other members of the semaphore.
 * down_trylock() and up() can be called from interrupt context, so we
 * have to disable interrupts when taking the lock.  It turns out various
 * parts of the kernel expect to be able to use down() on a semaphore in
 * interrupt context when they know it will succeed, so we have to use
 * irqsave variants for down(), down_interruptible() and down_killable()
 * too.
 *
 * The ->count variable represents how many more tasks can acquire this
 * semaphore.  If it's zero, there may be tasks waiting on the wait_list.
 */

#include <linux/compiler.h>
#include <linux/kernel.h>
#include <linux/export.h>
#include <linux/sched.h>
#include <linux/semaphore.h>
#include <linux/spinlock.h>
#include <linux/ftrace.h>

static noinline void __down(struct semaphore *sem);
static noinline int __down_interruptible(struct semaphore *sem);
static noinline int __down_killable(struct semaphore *sem);
static noinline int __down_timeout(struct semaphore *sem, long timeout);
static noinline void __up(struct semaphore *sem);

/**
 * down - acquire the semaphore
 * @sem: the semaphore to be acquired
 *
 * Acquires the semaphore.  If no more tasks are allowed to acquire the
 * semaphore, calling this function will put the task to sleep until the
 * semaphore is released.
 *
 * Use of this function is deprecated, please use down_interruptible() or
 * down_killable() instead.
 */
void down(struct semaphore *sem)
{
	unsigned long flags;

	raw_spin_lock_irqsave(&sem->lock, flags);
	if (likely(sem->count > 0))
		sem->count--;
	else
		__down(sem);
	raw_spin_unlock_irqrestore(&sem->lock, flags);
}
EXPORT_SYMBOL(down);

/**
 * down_interruptible - acquire the semaphore unless interrupted
 * @sem: the semaphore to be acquired
 *
 * Attempts to acquire the semaphore.  If no more tasks are allowed to
 * acquire the semaphore, calling this function will put the task to sleep.
 * If the sleep is interrupted by a signal, this function will return -EINTR.
 * If the semaphore is successfully acquired, this function returns 0.
 */
int down_interruptible(struct semaphore *sem)
{
	unsigned long flags;
	int result = 0;

	raw_spin_lock_irqsave(&sem->lock, flags);
	if (likely(sem->count > 0))
		sem->count--;
	else
		result = __down_interruptible(sem);
	raw_spin_unlock_irqrestore(&sem->lock, flags);

	return result;
}
EXPORT_SYMBOL(down_interruptible);

/**
 * down_killable - acquire the semaphore unless killed
 * @sem: the semaphore to be acquired
 *
 * Attempts to acquire the semaphore.  If no more tasks are allowed to
 * acquire the semaphore, calling this function will put the task to sleep.
 * If the sleep is interrupted by a fatal signal, this function will return
 * -EINTR.  If the semaphore is successfully acquired, this function returns
 * 0.
 */
int down_killable(struct semaphore *sem)
{
	unsigned long flags;
	int result = 0;

	raw_spin_lock_irqsave(&sem->lock, flags);
	if (likely(sem->count > 0))
		sem->count--;
	else
		result = __down_killable(sem);
	raw_spin_unlock_irqrestore(&sem->lock, flags);

	return result;
}
EXPORT_SYMBOL(down_killable);

/**
 * down_trylock - try to acquire the semaphore, without waiting
 * @sem: the semaphore to be acquired
 *
 * Try to acquire the semaphore atomically.  Returns 0 if the semaphore has
 * been acquired successfully or 1 if it it cannot be acquired.
 *
 * NOTE: This return value is inverted from both spin_trylock and
 * mutex_trylock!  Be careful about this when converting code.
 *
 * Unlike mutex_trylock, this function can be used from interrupt context,
 * and the semaphore can be released by any task or interrupt.
 */
int down_trylock(struct semaphore *sem)
{
	unsigned long flags;
	int count;

	raw_spin_lock_irqsave(&sem->lock, flags);
	count = sem->count - 1;
	if (likely(count >= 0))
		sem->count = count;
	raw_spin_unlock_irqrestore(&sem->lock, flags);

	return (count < 0);
}
EXPORT_SYMBOL(down_trylock);

/**
 * down_timeout - acquire the semaphore within a specified time
 * @sem: the semaphore to be acquired
 * @timeout: how long to wait before failing
 *
 * Attempts to acquire the semaphore.  If no more tasks are allowed to
 * acquire the semaphore, calling this function will put the task to sleep.
 * If the semaphore is not released within the specified number of jiffies,
 * this function returns -ETIME.  It returns 0 if the semaphore was acquired.
 */
int down_timeout(struct semaphore *sem, long timeout)
{
	unsigned long flags;
	int result = 0;

	raw_spin_lock_irqsave(&sem->lock, flags);
	if (likely(sem->count > 0))
		sem->count--;
	else
		result = __down_timeout(sem, timeout);
	raw_spin_unlock_irqrestore(&sem->lock, flags);

	return result;
}
EXPORT_SYMBOL(down_timeout);

/**
 * up - release the semaphore
 * @sem: the semaphore to release
 *
 * Release the semaphore.  Unlike mutexes, up() may be called from any
 * context and even by tasks which have never called down().
 */
void up(struct semaphore *sem)
{
	unsigned long flags;

	raw_spin_lock_irqsave(&sem->lock, flags);
	if (likely(list_empty(&sem->wait_list)))
		sem->count++;
	else
		__up(sem);
	raw_spin_unlock_irqrestore(&sem->lock, flags);
}
EXPORT_SYMBOL(up);

/* Functions for the contended case */

struct semaphore_waiter {
	struct list_head list;
	struct task_struct *task;
	bool up;
};

/*
 * Because this function is inlined, the 'state' parameter will be
 * constant, and thus optimised away by the compiler.  Likewise the
 * 'timeout' parameter for the cases without timeouts.
 */
static inline int __sched __down_common(struct semaphore *sem, long state,
								long timeout)
{
	struct task_struct *task = current;
	struct semaphore_waiter waiter;

	list_add_tail(&waiter.list, &sem->wait_list);
	waiter.task = task;
	waiter.up = false;

	for (;;) {
		if (signal_pending_state(state, task))
			goto interrupted;
		if (unlikely(timeout <= 0))
			goto timed_out;
		__set_task_state(task, state);
		raw_spin_unlock_irq(&sem->lock);
		timeout = schedule_timeout(timeout);
		raw_spin_lock_irq(&sem->lock);
		if (waiter.up)
			return 0;
	}

 timed_out:
	list_del(&waiter.list);
	return -ETIME;

 interrupted:
	list_del(&waiter.list);
	return -EINTR;
}

static noinline void __sched __down(struct semaphore *sem)
{
	__down_common(sem, TASK_UNINTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);
}

static noinline int __sched __down_interruptible(struct semaphore *sem)
{
	return __down_common(sem, TASK_INTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);
}

static noinline int __sched __down_killable(struct semaphore *sem)
{
	return __down_common(sem, TASK_KILLABLE, MAX_SCHEDULE_TIMEOUT);
}

static noinline int __sched __down_timeout(struct semaphore *sem, long timeout)
{
	return __down_common(sem, TASK_UNINTERRUPTIBLE, timeout);
}

static noinline void __sched __up(struct semaphore *sem)
{
	struct semaphore_waiter *waiter = list_first_entry(&sem->wait_list,
						struct semaphore_waiter, list);
	list_del(&waiter->list);
	waiter->up = true;
	wake_up_process(waiter->task);
}

```

可以看到，`interruptable`, `killable`, `uninterruptable` 这几种up/down的方式区别在于将task设置为什么状态，默认为uninterruptable。

### 使用

```c
    static ssize_t globarl_var(struct file *file, const char __user *ubuf,  
        size_t count,loff_t *offp)  
    {  
    //试图获得信号量，用可被信号打断方式  
            if(down_interruptible(&sema) < 0){  
                return -ERESTARTSYS;  
            }  
    //对共享资源(global_var)进行操作  
            if(copy_from_user(&global_var, buf, sizeof(int))){  
    //失败也要进行释放信号量，要不死锁了  
                up(&sema);  
                return -EFAULT;  
            }  
    //成功释放信号量     
            up(&sema);  
              
            return sizeof(int);  
    }  
```



#### 示例

```c
// /drivers/staging/vc04_services/interface/vchiq_arm/vchiq_util.h

typedef struct {
	int size;
	int read;
	int write;
	int initialized;

	struct semaphore pop;
	struct semaphore push;

	VCHIQ_HEADER_T **storage;
} VCHIU_QUEUE_T;

// ...

int vchiu_queue_init(VCHIU_QUEUE_T *queue, int size)
{
	WARN_ON(!is_pow2(size));

	queue->size = size;
	queue->read = 0;
	queue->write = 0;
	queue->initialized = 1;

	sema_init(&queue->pop, 0);
	sema_init(&queue->push, 0);

	queue->storage = kzalloc(size * sizeof(VCHIQ_HEADER_T *), GFP_KERNEL);
	if (queue->storage == NULL) {
		vchiu_queue_delete(queue);
		return 0;
	}
	return 1;
}

// ...

static void
free_pagelist(struct vchiq_pagelist_info *pagelistinfo,
	      int actual)
{
	unsigned int i;
	PAGELIST_T *pagelist   = pagelistinfo->pagelist;
	struct page **pages    = pagelistinfo->pages;
	unsigned int num_pages = pagelistinfo->num_pages;

	vchiq_log_trace(vchiq_arm_log_level, "free_pagelist - %pK, %d",
			pagelistinfo->pagelist, actual);

	/*
	 * NOTE: dma_unmap_sg must be called before the
	 * cpu can touch any of the data/pages.
	 */
	dma_unmap_sg(g_dev, pagelistinfo->scatterlist,
		     pagelistinfo->num_pages, pagelistinfo->dma_dir);
	pagelistinfo->scatterlist_mapped = 0;

	/* Deal with any partial cache lines (fragments) */
	if (pagelist->type >= PAGELIST_READ_WITH_FRAGMENTS) {
		char *fragments = g_fragments_base +
			(pagelist->type - PAGELIST_READ_WITH_FRAGMENTS) *
			g_fragments_size;
		int head_bytes, tail_bytes;
		head_bytes = (g_cache_line_size - pagelist->offset) &
			(g_cache_line_size - 1);
		tail_bytes = (pagelist->offset + actual) &
			(g_cache_line_size - 1);

		if ((actual >= 0) && (head_bytes != 0)) {
			if (head_bytes > actual)
				head_bytes = actual;

			memcpy((char *)page_address(pages[0]) +
				pagelist->offset,
				fragments,
				head_bytes);
		}
		if ((actual >= 0) && (head_bytes < actual) &&
			(tail_bytes != 0)) {
			memcpy((char *)page_address(pages[num_pages - 1]) +
				((pagelist->offset + actual) &
				(PAGE_SIZE - 1) & ~(g_cache_line_size - 1)),
				fragments + g_cache_line_size,
				tail_bytes);
		}

		down(&g_free_fragments_mutex);
		*(char **)fragments = g_free_fragments;
		g_free_fragments = fragments;
		up(&g_free_fragments_mutex);
		up(&g_free_fragments_sema);
	}

	/* Need to mark all the pages dirty. */
	if (pagelist->type != PAGELIST_WRITE &&
	    pagelistinfo->pages_need_release) {
		for (i = 0; i < num_pages; i++)
			set_page_dirty(pages[i]);
	}

	cleaup_pagelistinfo(pagelistinfo);
}
```



## glibc semaphore实现



### 介绍

* POSIX信号量

  非负整数

  常用于线程同步

  * 无名信号量

    常用于多线程间的同步，同时也用于相关进程间的同步。也就是说，无名信号量必须是多个进程（线程）的共享变量，无名信号量要保护的变量也必须是多个进程（线程）的共享变量，这两个条件是缺一不可的

    ​

    **支持操作**如下：

    * init

      ```c
      int sem_init(sem_t *sem, int pshared, unsigned int value);
      ```

      > 1) pshared==0 用于同一多线程的同步；
      >
      > 2) 若pshared>0 用于多个相关进程间的同步（即由fork产生的）

    * getvalue

      ```C
      int sem_getvalue(sem_t *sem, int *sval);
      ```

      > 取回信号量sem的当前值，把该值保存到sval中。
      >
      > 若有1个或更多的线程或进程调用sem_wait阻塞在该信号量上，该函数返回两种值：
      >
      > 1) 返回0
      >
      > 2) 返回阻塞在该信号量上的进程或线程数目
      >
      > linux采用返回的第一种策略。

    * wait

      sem_wait(或sem_trywait)相当于P操作，即申请资源。

      ```c
      int sem_wait(sem_t *sem);     // 这是一个阻塞的函数
      ```

      > 测试所指定信号量的值,它的操作是原子的。
      >
      > 若sem>0，那么它减1并立即返回。
      > 若sem==0，则睡眠直到sem>0，此时立即减1，然后返回。

      ```c
      int sem_trywait(sem_t *sem);   // 非阻塞的函数
      ```

      > 其他的行为和sem_wait一样，除了： 若sem==0，不是睡眠，而是返回一个错误EAGAIN。

    * post

      sem_post相当于V操作，释放资源。

      ```c
      int sem_post(sem_t *sem);
      ```

      > 把指定的信号量sem的值加1;
      >
      > 呼醒正在等待该信号量的任意线程。

    注意：在这些函数中，只有sem_post是信号安全的函数，它是可重入函数

    ​

    **操作样例**

    线程间

    ```c
    #include <pthread.h>
    #include <semaphore.h>
    #include <sys/types.h>
    #include <stdio.h>
    #include <unistd.h>

    int number;   // 被保护的全局变量
    sem_t sem_id;

    void* thread_one_fun(void *arg)
    {
        sem_wait(&sem_id);
        printf("thread_one have the semaphore\n");
        number++;
        printf("number = %d\n",number);
        sem_post(&sem_id);
    }

    void* thread_two_fun(void *arg)
    {
        sem_wait(&sem_id);
        printf("thread_two have the semaphore \n");
        number--;
        printf("number = %d\n",number);
        sem_post(&sem_id);
    }

    int main(int argc,char *argv[])
    {
        number = 1;
        pthread_t id1, id2;
        sem_init(&sem_id, 0, 1);
        
        pthread_create(&id1,NULL,thread_one_fun, NULL);
        pthread_create(&id2,NULL,thread_two_fun, NULL);
        pthread_join(id1,NULL);
        pthread_join(id2,NULL);
        
        printf("main,,,\n");
        
        return 0;
    }
    ```

    ​

    进程间 - 用mmap文件得到的内存地址来跨进程共享

    ```c
    #include <semaphore.h>
    #include <stdio.h>
    #include <errno.h>
    #include <stdlib.h>
    #include <unistd.h>
    #include <sys/types.h>
    #include <sys/stat.h>
    #include <fcntl.h>
    #include <sys/mman.h>

    int main(int argc, char **argv)
    {
        int fd, i,count=0,nloop=10,zero=0,*ptr;
        sem_t mutex;

        //open a file and map it into memory
        fd = open("log.txt",O_RDWR|O_CREAT,S_IRWXU);
        write(fd,&zero,sizeof(int));
        ptr = mmap( NULL,sizeof(int),PROT_READ |PROT_WRITE,MAP_SHARED,fd,0 );
        close(fd);

        /* create, initialize semaphore */
        if( sem_init(&mutex,1,1) < 0)  //
        {
            perror("semaphore initilization");
            exit(0);
        }

        if (fork() == 0)
        { /* child process*/
        	for (i = 0; i < nloop; i++)
    		{
                sem_wait(&mutex);
                printf("child: %d\n", (*ptr)++);
                sem_post(&mutex);
    		}
            exit(0);
    	}

        /* back to parent process */
    	for (i = 0; i < nloop; i++)
    	{
    		sem_wait(&mutex);
            printf("parent: %d\n", (*ptr)++);
            sem_post(&mutex);
    	}

        exit(0);
    }
    ```

  * 有名信号量

    和无名信号量共享sem_wait和sem_post函数。

    区别是有名信号量使用sem_open代替sem_init，另外在结束的时候要像关闭文件一样去关闭这个有名信号量。

    **操作**如下：

    * open

      ```c
      sem_t *sem_open(const char *name,  int oflag, mode_t mode , int value);
      ```

      > name是文件的路径名（在linux下，sem都是创建在/dev/shm目录下
      >
      > ，所以只需要文件名）；
      >
      > oflag 有O_CREAT或O_CREAT|EXCL两个取值；
      >
      > mode_t控制新的信号量的访问权限；
      >
      > value指定信号量的初始化值。

    * close

      ```c
      int sem_close(sem_t *sem);
      ```

      > sem_close() closes the named semaphore referred to by sem, allowing any resources that the system has allocated to the calling process for this semaphore to be freed.

    * unlink

      ```c
      int sem_unlink(const char *name);
      ```

      > sem_unlink() removes the named semaphore referred to by name.  The semaphore name is removed immediately.  The semaphore is destroyed once all other processes that have the semaphore open close it.
      >
      > 注意如果有任何的处理器或是线程引用这个信号量，sem_unlink()函数不会起到任何的作用。也就是说，必须是最后一个使用该信号量的进程来执行sem_unlick才有效。

  ​

  **使用样例**

  ```c
  // <u>File1: server.c </u>
  #include <sys/types.h>
  #include <sys/ipc.h>
  #include <sys/shm.h>
  #include <stdio.h>
  #include <semaphore.h>
  #include <sys/types.h>
  #include <sys/stat.h>
  #include <fcntl.h>

  #define SHMSZ 27

  char SEM_NAME[]= "vik";

  int main()
  {
      char ch;
      int shmid;
      key_t key;
      char *shm,*s;
      sem_t *mutex;

      //name the shared memory segment
      key = 1000;

      //create & initialize semaphore
      mutex = sem_open(SEM_NAME,O_CREAT,0644,1);
      if(mutex == SEM_FAILED)
      {
        perror("unable to create semaphore");
        sem_unlink(SEM_NAME);
        exit(-1);
      }

      //create the shared memory segment with this key
      shmid = shmget(key,SHMSZ,IPC_CREAT|0666);
      if(shmid<0)
  	{
          perror("failure in shmget");
          exit(-1);
  	}

      //attach this segment to virtual memory
      shm = shmat(shmid,NULL,0);

      //start writing into memory
      s = shm;
      for(ch='A';ch<='Z';ch++)
      {
          sem_wait(mutex);
          *s++ = ch;
          sem_post(mutex);
       }

      //the below loop could be replaced by binary semaphore
      while(*shm != '*')
      {
          sleep(1);
  	}

      sem_close(mutex);
      sem_unlink(SEM_NAME);
      shmctl(shmid, IPC_RMID, 0);
      exit(0);
  }
   

  // <u>File 2: client.c</u>
  #include <sys/types.h>
  #include <sys/ipc.h>
  #include <sys/shm.h>
  #include <stdio.h>
  #include <semaphore.h>
  #include <sys/types.h>
  #include <sys/stat.h>
  #include <fcntl.h>

  #define SHMSZ 27

  char SEM_NAME[]= "vik";

  int main()
  {
      char ch;
      int shmid;
      key_t key;
      char *shm,*s;
      sem_t *mutex;

      //name the shared memory segment
      key = 1000;

      //create & initialize existing semaphore
      mutex = sem_open(SEM_NAME,0,0644,0);
      if(mutex == SEM_FAILED)
      {
          perror("reader:unable to execute semaphore");
          sem_close(mutex);
          exit(-1);
      } 

      //create the shared memory segment with this key
      shmid = shmget(key,SHMSZ,0666);
      if(shmid<0)
      {
          perror("reader:failure in shmget");
          exit(-1);
      }

      //attach this segment to virtual memory
      shm = shmat(shmid,NULL,0);

      //start reading
      s = shm;
      for(s=shm;*s!=NULL;s++)
      {
          sem_wait(mutex);
          putchar(*s);
          sem_post(mutex);
      }

      //once done signal exiting of reader:This can be replaced by another semaphore
      *shm = '*';
      sem_close(mutex);
      shmctl(shmid, IPC_RMID, 0);
      exit(0);
  }
  ```

  ​


* SYSTEM V信号量

  一个或多个信号量的集合，它对应的是一个信号量结构体，这个结构体是为SYSTEM V IPC服务的，信号量只不过是它的一部分

  常用于进程间同步

  ...




### source code

```c
int
__new_sem_wait (sem_t *sem)
{
  if (__new_sem_wait_fast ((struct new_sem *) sem, 0) == 0)
    return 0;
  else
    return __new_sem_wait_slow((struct new_sem *) sem, NULL);
}

// ...

/* Fast path: Try to grab a token without blocking.  */
static int
__new_sem_wait_fast (struct new_sem *sem, int definitive_result)
{
  /* We need acquire MO if we actually grab a token, so that this
     synchronizes with all token providers (i.e., the RMW operation we read
     from or all those before it in modification order; also see sem_post).
     We do not need to guarantee any ordering if we observed that there is
     no token (POSIX leaves it unspecified whether functions that fail
     synchronize memory); thus, relaxed MO is sufficient for the initial load
     and the failure path of the CAS.  If the weak CAS fails and we need a
     definitive result, retry.  */
#if __HAVE_64B_ATOMICS
  uint64_t d = atomic_load_relaxed (&sem->data);
  do
    {
      if ((d & SEM_VALUE_MASK) == 0)
	break;
      if (atomic_compare_exchange_weak_acquire (&sem->data, &d, d - 1))
	return 0;
    }
  while (definitive_result);
  return -1;
#else
  unsigned int v = atomic_load_relaxed (&sem->value);
  do
    {
      if ((v >> SEM_VALUE_SHIFT) == 0)
	break;
      if (atomic_compare_exchange_weak_acquire (&sem->value,
	  &v, v - (1 << SEM_VALUE_SHIFT)))
	return 0;
    }
  while (definitive_result);
  return -1;
#endif
}

// ...

/* Slow path that blocks.  */
static int
__attribute__ ((noinline))
__new_sem_wait_slow (struct new_sem *sem, const struct timespec *abstime)
{
  int err = 0;

#if __HAVE_64B_ATOMICS
  /* Add a waiter.  Relaxed MO is sufficient because we can rely on the
     ordering provided by the RMW operations we use.  */
  uint64_t d = atomic_fetch_add_relaxed (&sem->data,
      (uint64_t) 1 << SEM_NWAITERS_SHIFT);

  pthread_cleanup_push (__sem_wait_cleanup, sem);

  /* Wait for a token to be available.  Retry until we can grab one.  */
  for (;;)
    {
      /* If there is no token available, sleep until there is.  */
      if ((d & SEM_VALUE_MASK) == 0)
	{
	  err = do_futex_wait (sem, abstime);
	  /* A futex return value of 0 or EAGAIN is due to a real or spurious
	     wake-up, or due to a change in the number of tokens.  We retry in
	     these cases.
	     If we timed out, forward this to the caller.
	     EINTR is returned if we are interrupted by a signal; we
	     forward this to the caller.  (See futex_wait and related
	     documentation.  Before Linux 2.6.22, EINTR was also returned on
	     spurious wake-ups; we only support more recent Linux versions,
	     so do not need to consider this here.)  */
	  if (err == ETIMEDOUT || err == EINTR)
	    {
	      __set_errno (err);
	      err = -1;
	      /* Stop being registered as a waiter.  */
	      atomic_fetch_add_relaxed (&sem->data,
		  -((uint64_t) 1 << SEM_NWAITERS_SHIFT));
	      break;
	    }
	  /* Relaxed MO is sufficient; see below.  */
	  d = atomic_load_relaxed (&sem->data);
	}
      else
	{
	  /* Try to grab both a token and stop being a waiter.  We need
	     acquire MO so this synchronizes with all token providers (i.e.,
	     the RMW operation we read from or all those before it in
	     modification order; also see sem_post).  On the failure path,
	     relaxed MO is sufficient because we only eventually need the
	     up-to-date value; the futex_wait or the CAS perform the real
	     work.  */
	  if (atomic_compare_exchange_weak_acquire (&sem->data,
	      &d, d - 1 - ((uint64_t) 1 << SEM_NWAITERS_SHIFT)))
	    {
	      err = 0;
	      break;
	    }
	}
    }

  pthread_cleanup_pop (0);
#else
  /* The main difference to the 64b-atomics implementation is that we need to
     access value and nwaiters in separate steps, and that the nwaiters bit
     in the value can temporarily not be set even if nwaiters is nonzero.
     We work around incorrectly unsetting the nwaiters bit by letting sem_wait
     set the bit again and waking the number of waiters that could grab a
     token.  There are two additional properties we need to ensure:
     (1) We make sure that whenever unsetting the bit, we see the increment of
     nwaiters by the other thread that set the bit.  IOW, we will notice if
     we make a mistake.
     (2) When setting the nwaiters bit, we make sure that we see the unsetting
     of the bit by another waiter that happened before us.  This avoids having
     to blindly set the bit whenever we need to block on it.  We set/unset
     the bit while having incremented nwaiters (i.e., are a registered
     waiter), and the problematic case only happens when one waiter indeed
     followed another (i.e., nwaiters was never larger than 1); thus, this
     works similarly as with a critical section using nwaiters (see the MOs
     and related comments below).

     An alternative approach would be to unset the bit after decrementing
     nwaiters; however, that would result in needing Dekker-like
     synchronization and thus full memory barriers.  We also would not be able
     to prevent misspeculation, so this alternative scheme does not seem
     beneficial.  */
  unsigned int v;

  /* Add a waiter.  We need acquire MO so this synchronizes with the release
     MO we use when decrementing nwaiters below; it ensures that if another
     waiter unset the bit before us, we see that and set it again.  Also see
     property (2) above.  */
  atomic_fetch_add_acquire (&sem->nwaiters, 1);

  pthread_cleanup_push (__sem_wait_cleanup, sem);

  /* Wait for a token to be available.  Retry until we can grab one.  */
  /* We do not need any ordering wrt. to this load's reads-from, so relaxed
     MO is sufficient.  The acquire MO above ensures that in the problematic
     case, we do see the unsetting of the bit by another waiter.  */
  v = atomic_load_relaxed (&sem->value);
  do
    {
      do
	{
	  /* We are about to block, so make sure that the nwaiters bit is
	     set.  We need release MO on the CAS to ensure that when another
	     waiter unsets the nwaiters bit, it will also observe that we
	     incremented nwaiters in the meantime (also see the unsetting of
	     the bit below).  Relaxed MO on CAS failure is sufficient (see
	     above).  */
	  do
	    {
	      if ((v & SEM_NWAITERS_MASK) != 0)
		break;
	    }
	  while (!atomic_compare_exchange_weak_release (&sem->value,
	      &v, v | SEM_NWAITERS_MASK));
	  /* If there is no token, wait.  */
	  if ((v >> SEM_VALUE_SHIFT) == 0)
	    {
	      /* See __HAVE_64B_ATOMICS variant.  */
	      err = do_futex_wait(sem, abstime);
	      if (err == ETIMEDOUT || err == EINTR)
		{
		  __set_errno (err);
		  err = -1;
		  goto error;
		}
	      err = 0;
	      /* We blocked, so there might be a token now.  Relaxed MO is
		 sufficient (see above).  */
	      v = atomic_load_relaxed (&sem->value);
	    }
	}
      /* If there is no token, we must not try to grab one.  */
      while ((v >> SEM_VALUE_SHIFT) == 0);
    }
  /* Try to grab a token.  We need acquire MO so this synchronizes with
     all token providers (i.e., the RMW operation we read from or all those
     before it in modification order; also see sem_post).  */
  while (!atomic_compare_exchange_weak_acquire (&sem->value,
      &v, v - (1 << SEM_VALUE_SHIFT)));

error:
  pthread_cleanup_pop (0);

  __sem_wait_32_finish (sem);
#endif

  return err;
}

// ...

/* Wait until at least one token is available, possibly with a timeout.
   This is in a separate function in order to make sure gcc
   puts the call site into an exception region, and thus the
   cleanups get properly run.  TODO still necessary?  Other futex_wait
   users don't seem to need it.  */
static int
__attribute__ ((noinline))
do_futex_wait (struct new_sem *sem, const struct timespec *abstime)
{
  int err;

#if __HAVE_64B_ATOMICS
  err = futex_abstimed_wait_cancelable (
      (unsigned int *) &sem->data + SEM_VALUE_OFFSET, 0, abstime,
      sem->private);
#else
  err = futex_abstimed_wait_cancelable (&sem->value, SEM_NWAITERS_MASK,
					abstime, sem->private);
#endif

  return err;
}
```



## 结论

用到了。




# 中断处理程序ISR对进程执行的打算 && 为什么ISR里不能使用信号量

TODO

## 引子 - 同上



## ref

* [关于LINUX在中断（硬软）中不能睡眠的真正原因](http://bbs.chinaunix.net/thread-2115820-1-1.html)

  ```
  其实这只是一个设计上的问题, 而并不是强制的. 只是针对Linux内核而言, 这是规矩. 
  LKD2上面说, 切换出去之后, 何时才能调度回来? 就是中断回来之后可能不会回到之前所依俯的那个进程了. 
  中断不能睡眠的的最大好处就是可以简化内核的设计. 如果说中断随时可以睡眠的话, 那么就必须考虑很多其它方面的事情, 比如睡眠之后又出现了
  同一IRQ号的中断又该怎么办, 等等. 
  其实, 如果自己能把握好, 中断中睡眠也是可以的. 但是必须能够保证这段代码具有足够的安全性与可靠性. 
  这是我的理解.
  ```

  **S**

  ```
  呵呵，我最喜欢这种讨论了。先来献丑了，说说我的看法。
  先把中断处理流程给出来

  1.进入中断处理程序--->2.保存关键上下文---->3.开中断（sti指令）--->4.进入中断处理程序的handler--->5.关中断（cli指令）---->6.写EOI寄存器（表示中断处理完成）---->7.开中断。
  复制代码

  硬中断：
  对应于上图的1、2、3步骤，在这几个步骤中，所有中断是被屏蔽的，如果在这个时候睡眠了，操作系统不会收到任何中断（包括时钟中断），系统就基本处于瘫痪状态（例如调度器依赖的时钟节拍没有等等……）

  软中断：
  对应上图的4（当然，准确的说应该是4步骤的后面一点，先把话说保险点，免得思一克又开始较真 ）。这个时候不能睡眠的关键是因为上下文。
  大家知道操作系统以进程调度为单位，进程的运行在进程的上下文中，以进程描述符作为管理的数据结构。进程可以睡眠的原因是操作系统可以切换不同进程的上下文，进行调度操作，这些操作都以进程描述符为支持。
  中断运行在中断上下文，没有一个所谓的中断描述符来描述它，它不是操作系统调度的单位。一旦在中断上下文中睡眠，首先无法切换上下文（因为没有中断描述符，当前上下文的状态得不到保存），其次，没有人来唤醒它，因为它不是操作系统的调度单位。
  此外，中断的发生是非常非常频繁的，在一个中断睡眠期间，其它中断发生并睡眠了，那很容易就造成中断栈溢出导致系统崩溃。

  如果上述条件满足了（也就是有中断描述符，并成为调度器的调度单位，栈也不溢出了，理论上是可以做到中断睡眠的），中断是可以睡眠的，但会引起很多问题.例如，你在时钟中断中睡眠了，那操作系统的时钟就乱了，调度器也了失去依据；例如，你在一个IPI（处理器间中断）中，其它CPU都在死循环等你答复，你确睡眠了，那其它处理器也不工作了；例如，你在一个DMA中断中睡眠了，上面的进程还在同步的等待I/O的完成，性能就大大降低了……还可以举出很多例子。所以，中断是一种紧急事务，需要操作系统立即处理，不是不能做到睡眠，是它没有理由睡眠。

  好了，罗嗦了一大堆，大家见仁见智，不要骂人就好。
  ```

  ```
  任何os，不管是分时os，还是实时os，不管是微内核，还是巨内核，在ISR中都不能进行进程切换。因为ISR不属于任何进程，而切换只能发生在进程上下文中。虽然ISR在执行过程中要使用进程的系统堆栈，但那只是借用，堆栈并不属于isr，而是属于进程。
  也可以从优先级角度来理解。任何进程，不论其优先级多高，也不能高过isr，所以不能剥夺isr对cpu的占有权去运行进程
  ```

  ```
  写得很好。赞一个。

  不过中断睡眠与否只是设计上的问题，不同的系统是不一样的设计。

  看看我自己机器上注册的ISR, IPL是10以下的都可以睡眠，里面包括了显卡，磁盘，网卡的常见外设的中断处理：

  bash-3.00# mdb -k
  Loading modules: [ unix genunix specfs dtrace uppc pcplusmp scsi_vhci ufs ip hook neti sctp arp usba uhci nca lofs zfs random audiosup sppp crypto ptm ipc ]
  > ::interrupts
  IRQ  Vect IPL Bus    Trg Type   CPU Share APIC/INT# ISR(s) 
  1    0x41 5   ISA    Edg Fixed  0   1     0x0/0x1   i8042_intr
  6    0x44 5   ISA    Edg Fixed  0   1     0x0/0x6   fdc_intr
  9    0x81 9   PCI    Lvl Fixed  0   1     0x0/0x9   acpi_wrapper_isr
  12   0x42 5   ISA    Edg Fixed  0   1     0x0/0xc   i8042_intr
  14   0x40 5   ISA    Edg Fixed  0   1     0x0/0xe   ata_intr
  15   0x43 5   ISA    Edg Fixed  0   1     0x0/0xf   ata_intr
  16   0x82 9   PCI    Lvl Fixed  0   1     0x0/0x10  nv_intr
  21   0x20 1   PCI    Lvl Fixed  0   4     0x0/0x15  uhci_intr, uhci_intr, uhci_intr, ehci_intr
  22   0x83 9   PCI    Lvl Fixed  0   1     0x0/0x16  audiovia823x_intr
  23   0x60 6   PCI    Lvl Fixed  0   1     0x0/0x17  gem_gld_intr
  208  0xd0 14         Edg IPI    all 1     -         kcpc_hw_overflow_intr
  209  0xd1 14         Edg IPI    all 1     -         cbe_fire
  224  0xe0 15         Edg IPI    all 1     -         apic_error_intr
  ```

  ```
  原帖由 Solaris12 于 2007-6-27 13:58 发表于 9楼  



  呵呵，Solaris的低优先级中断是可以睡眠的，时钟中断也可以睡眠。尽管系统会尽量保证中断线程不去睡眠。例如，磁盘驱动的ISR里使用DRIVEDR mutex, 实际上系统把它当作自适应锁，当获取锁失败时，它先看其 ...

  ISR(interrupt service routine)是不能睡眠的，我觉得你说的那个不是ISR，是IST(interrupt service thread).IST平时处于睡眠态，发生中断后，cpu执行ISR,在ISR中唤醒IST,中断服务的主体在IST中完成。引入IST后，一来可以减小内核体积，二来可以减小不可剥夺窗口，增强调度的实时性。WIN CE就是这样做的。不知Solaris的做法是否与此类似。请Solaris12兄指教

  ```

  **S**

  ```
  中断sleep, preempt和 实时性瓶颈介绍.

  原帖由 zx_wing 于 2007-6-27 10:09 发表于 4楼  
  呵呵，我最喜欢这种讨论了。先来献丑了，说说我的看法。
  先把中断处理流程给出来

  1.进入中断处理程序--->2.保存关键上下文---->3.开中断（sti指令）--->4.进入中断处理程序的handler--->5.关中 ...


  里面很多说法不是很同意, 个人认为中断处理handler不能sleep原因应该不是上面那些.

  我们都是从理论讲下面这些问题, 因为linux在很多地方做了保护, 所以直接sleep或者schedule()会导致内核异常.

  首先分清楚, 我们讨论的是不能sleep, 而不是不能preempt.

  1. 毫无疑问, 在关中断的时候不能sleep, 这点大家都知道, 因为时钟中断无法触发. 但不是所有情况下, 在关中断时sleep都会导致系统死掉, 在SMP的情况下, 可能系统不会死掉.

  2.  中断的handler能否sleep? 
       这其实和"中断没有自己的上下文"无关. CPU没有关中断, 中断有自己的上下文, 中断的上下文就是抢占的任务A的上下文.
       和栈溢出也没有关系, 现在的中断都是可以嵌套的, 如果中断sleep只会让后面的中断抢占其他任务, 根本不存在栈溢出问题, 不过现在内核的4K中断单独栈会有问题. 这会导致栈被破坏.

  假设中断sleep了, 在调度的时候, 内核将中断的CS:eip和SS:esp保存在被抢占任务A的thread_info中, 当任务A被重新唤醒的时候, 任务A从中断的CS:eip开始执行, 这也能正常执行下去, 中断执行完后, 从ret_from_intr中返回. 可以恢复任务A的抢占前的场景. 

  Linux内核要实现成这样, 必须解决下面问题:
      中断sleep会增加普通任务的不确定性, 普通任务执行的时间, 实时性都得不到保障.
      和中断共享中断号的中断会受到影响, 现在的内核设置了INPROGRESS标志.
      中断因为借用了被抢占任务的上下文, 所以中断的处理受到任务上下文属性的限制.
      等等很多其他问题, 总之, 中断sleep会导致被抢占任务的不确定性, 并可能导致其他中断受影响.

  总结:
      异步异常(中断)handler不是没有上下文, 而是没有固定的上下文,  如果使用被抢占的任务作为上下文, 一,自身的处理无法得到实时保障,导致系统不确定性, 二,任务受到影响.

  如何解决:
      给中断handler提供固定的内核线程上下文!!
      这样, 中断不能sleep, 但中断的handler可以sleep! 
      为每个中断号创建一个内核任务, 中断入口函数do_irq只是唤醒相应的中断任务, 中断任务去执行相应的handler.

  好处: 
       提高了系统的实时性. 后面可以详细讲.
  坏处:
       降低了中断, 软中断的实时性, 所以不是所有的中断handler都可以在固定内核任务上下文中处理. 一般来说, 时钟中断必须保证其实时性, 所以留在中断上下文中.

  介绍: Linux系统的实时性瓶颈在哪里?? 
      一个实时性系统, 必须保证: 系统中优先级高的任务, 被唤醒后, 在很小的可控的延时内, CS:eip指令得到执行.
      一个好的实时性系统, 必须保证: 系统中的所有等待运行的任务, 可以在一个固定的可接受的延时内, CS:eip指令得到执行.
      这些延时包括 中断响应延时, 中断处理延时, 调度响应和调度处理延时.
  复制代码


  试想现有的系统, 一个任务可能在以下上下文中被唤醒:
  1. 中断上下文, 如dma数据传输完成等等设备驱动.

          中断上下文唤醒任务后, 任务被加入到running队列, 返回, 继续执行中断, 中断执行完成后, 执行软中断, 中间可能会出现中断嵌套. 直到最后ret_from_intr, 才会判断是否需要抢占当前任务. 然后调用schedule(). 从队列被加入running队列到schedule()函数真正开始执行, 这段时间是中断处理延时+调度响应延时. 

    如何缩短这部分延时和我们前面讨论的东西很有关.
      正是因为中断,软中断不能preempt, 不能sleep, 导致了系统的实时性变差. 而在这些时间中, 中断handler和软中断handler消耗绝大部分时间. 
      设想一下, 如果中断handler和软中断handler放在专门的内核任务中执行, 中断handler中唤醒任务A, wakeup中通过优先级判断handler任务是否需要被任务A抢占, 如果需要, 设置handler任务的NEED_RESCHEDULE标志, 调用resched_task()可以马上进入schedule(), 其中的延时非常小, 而且非常稳定. 当然, 可能wakeup后, 立即有中断到来, 但因为中断执行路径变得非常短, 只是唤醒响应的handler任务, 可能只需要100行以内的代码.所以这些时间可以忽略不计. 这种做法可以极大提高系统的实时性.
      
  2. 软中断上下文: 如定时器到期, 目的地是本地的报文送到socket层. 等等
          软中断的情况和中断类似, 可以通过将软中断线程化, 提高系统实时性.

  3. 普通任务上下文, 如任务间通信等等.
     普通任务一旦在内核中执行了spin_lock(), 其他任务无法抢占这个CPU, 即使另外优先级高的任务不和它共享资源, 也无法及时得到调度. 当CPU变多, 内核代码变大的时候, 这个问题也变得非常突出, 所以spin_lock()也是一个影响系统实时性的设计. 如果将spin_lock变成可以抢占的锁, 会是怎样? 如果spin_lock可以抢占, 一旦任务B抢占了任务A, 而任务A执行了spin_lock(xxx), 恰好任务B也执行spin_lock(xxx), 必然导致内核死锁. 如果spin_lock()可以抢占, 且可以sleep(), 结果又会怎样. 任务B执行spin_lock(xxx)必然导致自己sleep, 这时任务A可以接着执行spin_unlock(xxx),唤醒任务B. 这时又有一个优先级反转问题需要解决, 假设任务B的优先级最高, 任务A最低, 任务C中等, B因为拿不到xxx锁而sleep, 重新调度, 结果调度到任务C执行, 任务B因此丧失了优先级优势, 这种情况在嵌入式系统中可能会导致很严重的问题. 所以任务A必须继承任务B的优先级, 重新调度的时候才能调度到任务A先运行.
     
  --------------------------------------------------------------------------------------
  上面这些系统问题的改正可以提高系统的实时性, 但整个内核的编程模型会变得更复杂. 这些东西就是Ingo Molnar在2005年实现的Realtime Patch中的核心思想, 但在2006年的Kernel Summit中, 引发了下面的讨论:

  http://lwn.net/Articles/191782/

  注意下面这段话.
  The question was asked: why bother with sleeping locks? Making locks preemptible is seen by some as a way of papering over the real problem: long lock hold times. Why not simply fix those? The answer comes in a couple of parts:

      * Extensive efforts have been expended toward fixing lock problems for many years, and those efforts will continue into the future. The use of sleeping locks is not being used as an excuse to avoid fixing code which holds locks for too long.

      * Ensuring realtime response in the absence of preemptible locks requires auditing the entire body of kernel source - all eight million lines or so. That's a big job, and one which is hard to keep up with in an environment where nearly ten thousand lines of code are being changed every day. Sleeping locks reduce the audit requirements to a couple thousand lines - a much more tractable problem. For those who need realtime response, guaranteed, that is a good deal. 

  因为众多的争议, 中断和软中断的线程化和spin_lock的可sleep化没有合入主流内核中.

  如果realtime patch合并到主流内核中, 可以满足: 系统中优先级高的任务, 被唤醒后, 在很小的可控的延时内, CS:eip指令得到执行.

  但不能保证低优先级的时延, 这正是CFS要解决的问题, 设想一下, 要让系统中的任何优先级的任务在一定的时间内得到执行, 必然要求等待时间长的任务优先得到执行, CFS就是用等待时间来作为调度的依据, 而优先级居次. 有时间在讨论CFS的实现.

  [ 本帖最后由 xiaozhaoz 于 2007-6-28 00:41 编辑 ]
  ```

  ​

  ```
  自陷就是TRAP，LINUX的EXCEPTION－异常，有进程上下文。

  TRAP，相当于一个软中断（INT 1， INT 3， 断点，单步等），和软中断调用的系统调用（INT 21， INT 80)几乎一样，属于当前进程，进入内核使用进程的内核栈。唯一不同的是，系统调用的软中断在用户程序中的位置相对固定，而TRAP相对不固定。

  假定INT 0是被0除TRAP，你在USER中执行A ＝ 1／0和执行INT 0是一样的，而INT 0 和INT 80也是一样的。用户程序执行INT 80有进程CONTEXT, 执行INT 0也一样有进程CONTEXT.

  可以看出，TRAP(比如INT 0)的PROCESS CONTEXT和执行系统调用INT 80后的PROCESS CONTEXT是一样的。所以TRAP中如果睡眠了，是可以回来的。

  而中断没有进程上下文。调度后无法回来. 

  如果不想回来了, 中断中也是可以睡眠的.

  正因为TRAP和中断有如此不同，LINUX系统中才对于INTERRUPT 和 EXCEPTION的处理才是非常不同。

  我理解的前面的说的中断和进程无关大概就是这个意思（？）
  ```

  ```
  原帖由 思一克 于 2007-6-28 11:05 发表于 31楼  
  中断当然有自己的CONTEXT。但没有（准确说经常没有）进程相关的CONTEXT。
  你看2.6.13 KERNEL，IRQ使用 自己的STACK，如果在中断中schedule()了，能正确回来吗？




  你再编译的时候, 把4K的stack的选项不要选上, 中断和软中断就不会使用自己的栈, 而是使用被抢占任务的栈了.

  所以栈不是中断不能sleep的原因.
  ```

  ```
  原帖由 zx_wing 于 2007-6-28 10:56 发表于 29楼  

  此外，我想lz对上下文一词还有点误解。
  上下文（context）表示当前cpu的状态，包括各种标志及寄存器的值。这里中断是运行在自己的上下文而不是进程的上下文。如果是运行在进程上下文的话，中断处理就不需要在 ...


  nod, 在书里都是这样写的, 
  但是实际情况下比这个要复杂, 内核中光有上下文无法完成调度切换的工作, 

  所以在Linux Kernel中, 我一般将上下文指作可以协助Kernel完成调度的东西, 就是内核task, thread_info结构, + CPU寄存器.
  ```

  ```
  原帖由 augustusqing 于 2007-6-28 11:41 发表于 38楼  
  在中断跟内核用的是同一个栈的情况下，如果系统允许某个handler中可以sleep，那么在不可预知的任何时候，任何一个内核线程/进程在执行的时候，恰好来了上面的中断并执行到了handler，则这个内核线程/进程就"中奖"了，就会sleep，而只要这个handler是在开中的情况下运行的，它是可以被其他线程/进程唤醒的，关键是系统中所有的线程/进程都有这个"中奖"机会，哈哈

  这样理解对吗？


  对, 就是这个意思, 
  所以这种系统的不确定性就很大.  
  而现在的中断除了不sleep, 不能preempt之外, 对任务的影响也想你说的那样"中奖"式的, 所以现在系统的实时性是无法保证的!!

  解决这个问题的方法就是让handler只能在固定的上下文中sleep, 当然能不sleep最好不要sleep. 所以就有了将handler放到专门内核线程中处理的想法.

  如果内核的实时性足够好, 那么handler线程的执行也可以得到保证.
  ```

  ```
  我个人的看法, 相信大家会有更多的想法.

  一句话的总结:
  中断sleep会导致系统工作异常. 

  三句话总结:
      1. 中断sleep会增加 任务, 系统的不确定性
      2. 和中断共享中断号的中断会受到影响.
      3. 中断的处理受到被抢占任务上下文属性的限制.

  解释和解决的方法看19楼.

  总之, 我们都是在玩文字游戏, 中断没有固定上下文(context), 而不是没有上下文.

  PS, 正是因为Linux是一个通用的操作系统, 所以必须让用户可以配置成嵌入式实时模式, 所以必须考虑实时性因素!
  ```

  ```
  原帖由 思一克 于 2007-6-28 14:51 发表于 46楼  
  我看了19楼的帖子，

  觉得
  中断和软中断的线程化和spin_lock的可sleep化这两个并不能提高系统的实时性。

  比如spinlock, 就是为了短暂需要lock的时候让CPU空等待。这时比用可以sleep的锁要节省CPU而不是浪费。因为调度的耗费可能要比SPIN的耗费多的多。

  linux的中断是半THREAD化的。你可以增加工作在THREAD（softirqd)中的比重，增加后，系统反映更慢了。比如你打一个字，一个网络包的处理，如果都用THREAD做，响应应该是慢一些。因为调度的原因 。

  如果不对，请批驳。



  好几个同事问过同样的问题. 

  这个问题已经脱离了本贴的原意, 如果有兴趣, 可以另外开贴讨论.

  实时性的必须保证, 系统在任何情况下, 可以在一定的时间内执行到某个任务.

  1. 你的比较尺度有问题, 你是拿现有系统的最好情况和realtime patch系统的最坏情况比较.
  2. 现有系统的最坏情况, 延时可能有几十毫秒, 察看19楼的描述. 而realtime patch的系统只有几十us(不要低估了我们CPU的处理能力, 而且上限制是可以计算的.

  具体你可以在网上找到大量的测试报告.

  [ 本帖最后由 xiaozhaoz 于 2007-6-28 16:53 编辑 ]
  ```

  ```
  原帖由 思一克 于 2007-6-28 14:51 发表于 46楼  
  我看了19楼的帖子，

  比如spinlock, 就是为了短暂需要lock的时候让CPU空等待。这时比用可以sleep的锁要节省CPU而不是浪费。因为调度的耗费可能要比SPIN的耗费多的多。

  linux的中断是半THREAD化的。你可以增加工作在THREAD（softirqd)中的比重，增加后，系统反映更慢了。比如你打一个字，一个网络包的处理，如果都用THREAD做，响应应该是慢一些。因为调度的原因


  1. Solaris的自适应锁比较聪明，发现有人已经占用前就会去看锁当前的所有者是否在 CPU上运行，如果是，就自旋，如果不是就睡眠。


  2. Solaris的中断线程是线程池，预先创建好的，kthread_t的结构在中断栈底部，总是就是为了减少线程化带来的overhead。
  ```

  ```
  原帖由 zx_wing 于 2007-6-29 11:32 发表于 55楼  

  Solaris上锁的持有者可以睡眠？那死锁怎么办？



  我说的是自适应锁，Solaris的mutex本质上分为自适应和自旋两种。

  1.不允许睡眠的上下文要用自旋锁，例如，IPI等高优先级中断。
  2.允许睡眠的上下文用自适应锁，会动态判断自旋还是睡眠。一般低优先级中断用的就是这种锁，例如网卡，磁盘等中断。
  ```

  ​


## 结论

前面提到的中断处理流程：

1. 进入中断处理程序


2. 保存关键上下文
3. 开中断（sti指令）
4. 进入中断处理程序的handler
5. 关中断（cli指令）
6. 写EOI寄存器（表示中断处理完成）
7. 开中断



### 真的不能？



### 为什么不能？

#### 背景： 一个硬中断的完整处理过程

ref: [硬中断的完整处理过程](http://www.cnblogs.com/super-king/p/3296201.html)



```
★ CPU做的工作：
CPU收到中断/异常信号；
CPU判断当前CPL级别如果等于3，则导致堆栈切换3->0，堆栈切换过程：
a. CPU从当前TR指向的TSS中读取SS0和ESP0；
b. CPU将当前的【SS:ESP】寄存器内容临时保存起来，假设为SSt和ESPt；
c. CPU将SS0和ESP0恢复到【SS:ESP】寄存器中；
d. CPU将临时保存的SSt和ESPt压入当前的堆栈【SS:ESP】中（其实就是SS0和ESP0指向的堆栈)；
CPU判断当前CPL级别如果等于0，则不会有2中的步骤；
CPU将EFLAGS、CS、EIP依次压入当前的堆栈【SS:ESP】中；
如果当前是异常，则CPU将异常码error code压入当前的堆栈【SS:ESP】中，否则会省略该步骤；
对于中断，CPU清零当前EFLAGS->IF位，即关闭CPU中断使能，对于异常，CPU则不会清零该位；
执行对中断/异常处理程序的调用；

注：对中断/异常处理程序的要求，为了正常的从中断/异常处理程序中返回，中断/异常处理程序必须使用IRET指令返回，该指令会依次出栈EIP、CS和 EFLAGS，比RET多一个EFLAGS，当EFLAGS恢复后，由于原来保存时IF位为1，因此这里相当于CPU中断使能又打开了；
★ Linux内核做的工作 (2.4 kernel)：
1. 中断向量表-->common_interrupt：
common_interrupt:
SAVE_ALL
pushl $ret_from_intr
SYMBOL_NAME_STR(call_do_IRQ):
jmp SYMBOL_NAME_STR(do_IRQ);

SAVE_ALL保存所有CPU没有保存的寄存器，由于do_IRQ是函数，这里直接调用jmp，（一般用call来调用函数，call会导致 push EIP，但jmp不会）这样当do_IRQ返回调用ret（ret相当于pop EIP）时，会弹出栈中最后一个元素到EIP，很显然这里就是 ret_from_intr，也就是说，从do_IRQ中返回后，会跳转到ret_from_intr处继续执行；
2. 来到do_IRQ：
a. 首先给硬中断计数加1,irq_enter(cpu, irq)也就是：++local_irq_count(cpu)；每进入一个硬中断处理函数前，local_irq_count(cpu)计数便被加1，处理完毕后减1；
b. 如果当前设备中断处理函数可以在中断打开的情况下运行，则调用sti将EFLAGS.IF置位，打开硬中断使能；
c. 调用request_irq注册的设备硬中断处理函数；
d. 无论EFLAGS.IF是否为0，都调用cli将EFLAGS.IF清零，将硬中断使能关闭；
e. 给硬中断计数减1,irq_enter(cpu, irq);该函数其实就是：--local_irq_count(cpu);
f. 如果此时有软中断需要运行（如在前面的硬中断处理函数中调用__cpu_raise_softirq），则进入do_softirq中处理软中断，关于do_softirq中的处理步骤见3；
e. do_IRQ执行ret，返回到ret_from_intr。
3. do_softirq：
a. 首先判断当前是否还有没有处理完毕的硬中断处理程序或软中断处理程序，如果有，则直接退出该函数。
b.将软中断处理计数加1，local_bh_disable()也就是local_bh_count(cpu)++；每进入do_softirq准备进 行处理软中断前，local_bh_count(cpu)计数便被加1，软中断处理函数处理完毕后，在do_softirq返回前，将其值减1；
c. 无论EFLAGS.IF是否为0，都调用cli将EFLAGS.IF清零，将硬中断使能关闭，处理些软中断标志位的问题，随后调用sti将EFLAGS.IF置位，打开硬中断使能；
d. 执行软中断处理函数；
e. 调用cli将EFLAGS.IF清零，将硬中断使能关闭，处理些软中断标志位的问题；
f. 将软中断处理计数减1，local_bh_enable()也就是local_bh_count(cpu)--；
g. 返回到2.e中；
4. ret_from_intr：
ENTRY(ret_from_intr)
GET_CURRENT(%ebx)
movl EFLAGS(%esp),%eax
movb CS(%esp),%al
testl $(VM_MASK | 3),%eax
jne ret_with_reschedule
jmp restore_all

在这段代码中，通过"testl $(VM_MASK |3),%eax"检测中断前夕寄存器EFLAGS的高6位和代码段寄存器CS的内容，来判断中断前夕CPU是否运行于VM86模式、用户空间还是系统空 间，对VM86这里不讲了，但是我们知道CS最低两位代表着中断发生时CPU的运行级别CPL，我们知道Linux只采用两种运行级别，系统为0，用户为 3，所以，如果CS的最低两位为非0，那就说明中断发生于用户空间。如果中断发生于系统空间，控制就直接转移到restore_all，而如果发生于用户 空间，则转移到ret_with_reschedule。在restore_all中恢复1中保存的寄存器，随后调用iret恢复EIP、CS、 EFLAGS返回到中断发生时的状态。
5. ret_with_reschedule：
a. 如果发现当前进程的need_resched==1，则会调用schedule；
b. 如果发现还有待需要处理的软中断，则会调用do_softirq；

说明：能够走到ret_with_reschedule处，从4中可知，该中断前一定位于用户层，而且不可能有可中断的硬中断或软中断没有执行，也就是说 到达这里in_interrupt必然为0。为什么这里要说不可能有可中断的硬中断或软中断没有执行呢？可中断的硬中断或软中断必然是被中断或者异常所打 断的，当后者处理完毕后，从4中可知，由于后者发生前位于内核态（也就是可中断的硬中断或软中断处理过程中的那个点），故控制就直接转移到 restore_all，即返回到了可中断的硬中断或软中断被打断时的那个点，继续处理完毕，可见，到达这里，必然不存在可中断的硬中断或软中断未被执 行。
附 注：关于in_interrupt宏，也就是(local_irq_count(__cpu) +local_bh_count(__cpu) !=0)。什么情况下会导致进入do_softriq时，in_interrupt不为0呢？第一种，如果当前正在处理可中断的硬中断处理函数，假设此时 来了另一个通道的硬中断，将导致当前硬中断处理函数被中断，进入do_IRQ，随后处理新来的硬中断处理函数，当处理完毕后，到达do_softirq， 由2中可知，此时local_irq_count(__cpu)被原先的硬中断加1，由于其还没有处理完毕，故--local_irq_count (cpu)还没来得及执行，因此local_irq_count(__cpu)>0，也就是in_interrupt！=0；第二种，如果当前正在 do_softirq中处理软中断处理函数，现在来了个硬中断，将导致当前软中断处理函数被中断，进入do_IRQ，随后处理新来的硬中断处理函数，当处 理完毕后，又来带到了do_softirq，由3中可知，此时local_bh_count(cpu)被前一个do_softirq加1了，但是由于其是 中途被中断的，故local_bh_count(cpu)--还没来得及执行，因此local_bh_count(__cpu)>0，也就是 in_interrupt！=0；第三种就是综合第一种和第二种两种情况。

★ Linux内核做的工作 (2.6 kernel)：
首先介绍中断向量的范围:
  -   19 (0x0   -   0x13) 非屏蔽中断和异常
 -   31 (0x14  -   0x1f) Intel 保留
 -  127 (0x20  -   0x7f) 外部中断 (IRQ)
        (0x80)            系统调用
-  238 (0x81  -  0xee) 外部中断 (IRQ)
        (0xef)          本地APIC时钟中断
        (0xf0)          本地APIC高温中断 (P4模型中引人)
-  250 (0xf1  -  0xfa) linux 将来使用
-  253 (0xfb  -  0xfd) 处理器间中断
        (0xfe)          本地APIC错误中断
        (0xff)          本地APIC伪中断 (CPU屏蔽某个中断是产生)

在init_IRQ中
for (i = 0; i < (NR_VECTORS - FIRST_EXTERNAL_VECTOR); i++) {
    int vector = FIRST_EXTERNAL_VECTOR + i;
    if (i >= NR_IRQS)
        break;
    if (vector != SYSCALL_VECTOR)
        set_intr_gate(vector, interrupt[i]);
}
设置了中断函数的入口地址. 那么 interrupt 在哪那？
在entry.S中有
    .data
ENTRY(interrupt)
    .text
    vector=0
ENTRY(irq_entries_start)
    RING0_INT_FRAME
    .rept NR_IRQS
    ALIGN
    .if vector
    CFI_ADJUST_CFA_OFFSET -4
    .endif
1:      pushl $~(vector)
    CFI_ADJUST_CFA_OFFSET 4
    jmp common_interrupt
    .data
    .long 1b
    .text
    vector=vector+1
    .endr
    ALIGN
    //看interrupt 在此初始化，所有中断都会调用到下面的标记
    common_interrupt:
    SAVE_ALL
    TRACE_IRQS_OFF
    movl %esp,%eax //栈顶地址被放到eax中
    call do_IRQ
    jmp ret_from_intr
    CFI_ENDPROC

    现在来看 do_IRQ -> __do_IRQ
    首先: struct irq_desc *desc = irq_desc + irq;
    struct irq_desc {
        ......
        struct irqaction  * action; //IRQ action list
        ......
    };
函数中
......
status |= IRQ_PENDING; /* we _want_ to handle it */

action = NULL; // action  NULL
//如果没有任何cpu正在处理irq且irq线没有被关闭，action才被赋值
if (likely(!(status & (IRQ_DISABLED | IRQ_INPROGRESS)))) {
    action = desc->action;
    status &= ~IRQ_PENDING; /* we commit to handling */
    status |= IRQ_INPROGRESS; /* we are handling it */
}
desc->status = status;
......
然后不管怎样如果要处理中断会调用 handle_IRQ_event
其中主循环为
do {
    ret = action->handler(irq, action->dev_id, regs); //调用具体中断处理函数
    if (ret == IRQ_HANDLED)
        status |= action->flags;
    retval |= ret;
    action = action->next;
} while (action);

struct irqaction {
    irqreturn_t (*handler)(int, void *, struct pt_regs *); //中断处理函数
    unsigned long flags;
    cpumask_t mask;
    const char *name;
    void *dev_id;
    struct irqaction *next;
    int irq;
    struct proc_dir_entry *dir;
};

下面讲一下怎样安装的中断处理函数.
安装中断处理程序主要的函数是
int request_irq(unsigned int irq, irqreturn_t (*handler)(int, void *, struct pt_regs *), unsigned long irqflags, const char *devname, void *dev_id)
函数中主要会调用 setup_irq 会把分配的 struct irqaction 加入到 struct irq_desc *desc = irq_desc + irq; 中.
其中
......
#if defined(CONFIG_IRQ_PER_CPU)
if (new->flags & IRQF_PERCPU) //可以在cpu上嵌套执行中断处理函数
    desc->status |= IRQ_PER_CPU;
#endif
......
```



#### 背景： 单独中断栈 和 非单独中断栈

* 默认linux内核使用单独的中断栈；
* 可以修改编译选项使得内核使用被抢占的任务的栈



#### 解释



* 首先，关中断期间不能

  因为期间时钟中断无法触发，而执行流又让出了等待唤醒，那么就gg了（前面提到在SMP的情况下, 可能系统不会死掉）

* 然后，在开中断期间（handler中）： 也不能

  ​

  ​



### 怎么（使得）不能？

* `linux在很多地方做了保护, 所以直接sleep或者schedule()会导致内核异常`






# 摘录：[磁盘写导致IO wait飙升的问题深入排查](http://sanwen.net/a/tfxhvoo.html) or [local](resource/磁盘写导致IO wait飙升的问题深入排查.htm)



联想到我们这边ssd high wait的情况，是不是也可能是写阻塞读导致wait增高？ 发生问题时是大量拖图也即cache大量更新的时候，也即写操作很多，而cache本身是读操作也很多的，于是...

如果是的话，解决办法呢？ 毕竟当时大约读写分别为20/60MB/s而IOPS读写分别为3K/1.2W，离应有性能上限还远...









