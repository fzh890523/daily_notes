
# 小坑： [HBase-user] IllegalArgumentException: Connection is null or closed when calling HConnection.getTable()

ref: [](http://grokbase.com/t/hbase/user/151kgpzbcp/illegalargumentexception-connection-is-null-or-closed-when-calling-hconnection-gettable)


```
Hi Calvin,

An HConnection created via
HConnectionManager#createConnection(Configuration) is an "unmanaged"
connection, meaning it's lifecycle is managed by your code. Are you calling
HConnection#close() on that instance someplace?

Please notice that these are different semantics from the previous
HConnection#getConnection(Configuration), which returns a "managed"
connection, one who's lifecycle is managed by the HBase client.

-n
```


如文中提到的，`HConnectionManager#createConnection(Configuration)`得到的是一个`unmanaged`，也即连接是否可用需要应用层去`check`，也即使用方式为`check--and--reconn-or-use`。

# jcmd/jps看不到es同时jstat提示not found问题
```
sudo -u elasticsearch bash -c 'jstat -gcutil `cat /var/run/elasticsearch.pid` 3s 100'
```

需要切换到es的运行用户`elasticsearch`去执行。
这一点比较极端，其他场景的情况，只是root用户去jstack其他用户运行的java程序会很慢甚至无响应。 es的情况直接看不到确实很奇怪。

TODO 了解下背后的机制

# kafka的一些参数解释
> ref: [apache kafka系列之客户端开发-java](http://blog.csdn.net/lizhitao/article/details/37811291)

## consumer
```
# zookeeper连接服务器地址，此处为线下测试环境配置(kafka消息服务-->kafka broker集群线上部署环境wiki)
# 配置例子："127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002"
zookeeper.connect=192.168.2.225:2181,192.168.2.225:2182,192.168.2.225:2183/config/mobile/mq/mafka
# zookeeper的session过期时间，默认5000ms，用于检测消费者是否挂掉，当消费者挂掉，其他消费者要等该指定时间才能检查到并且触发重新负载均衡
zookeeper.session.timeout.ms=5000
zookeeper.connection.timeout.ms=10000
#当consumer reblance时，重试失败时时间间隔。
zookeeper.sync.time.ms=2000
 
#指定消费组
group.id=xxx
# 当consumer消费一定量的消息之后,将会自动向zookeeper提交offset信息 
# 注意offset信息并不是每消费一次消息就向zk提交一次,而是现在本地保存(内存),并定期提交,默认为true
auto.commit.enable=true
# 自动更新时间。默认60 * 1000
auto.commit.interval.ms=1000
 
# 当前consumer的标识,可以设定,也可以有系统生成,主要用来跟踪消息消费情况,便于观察
conusmer.id=xxx 
 
# 消费者客户端编号，用于区分不同客户端，默认客户端程序自动产生
client.id=xxxx
# 最大取多少块缓存到消费者(默认10)
queued.max.message.chunks=50
# 当有新的consumer加入到group时,将会reblance,此后将会有partitions的消费端迁移到新 
# 的consumer上,如果一个consumer获得了某个partition的消费权限,那么它将会向zk注册 
# "Partition Owner registry"节点信息,但是有可能此时旧的consumer尚没有释放此节点, 
# 此值用于控制,注册节点的重试次数. 
rebalance.max.retries=5
# 获取消息的最大尺寸,broker不会像consumer输出大于此值的消息chunk
# 每次feth将得到多条消息,此值为总大小,提升此值,将会消耗更多的consumer端内存
fetch.min.bytes=6553600
# 当消息的尺寸不足时,server阻塞的时间,如果超时,消息将立即发送给consumer
fetch.wait.max.ms=5000
socket.receive.buffer.bytes=655360
 
# 如果zookeeper没有offset值或offset值超出范围。那么就给个初始的offset。有smallest、largest、
# anything可选，分别表示给当前最小的offset、当前最大的offset、抛异常。默认largest
auto.offset.reset=smallest
# 指定序列化处理类(mafka client API调用说明-->3.序列化约定wiki)，默认为kafka.serializer.DefaultDecoder,即byte[]
derializer.class=com.meituan.mafka.client.codec.MafkaMessageDecoder
```

## producer
```
#指定kafka节点列表，用于获取metadata，不必全部指定
metadata.broker.list=192.168.2.105:9092,192.168.2.106:9092
# 指定分区处理类。默认kafka.producer.DefaultPartitioner，表通过key哈希到对应分区
#partitioner.class=com.meituan.mafka.client.producer.CustomizePartitioner
 
# 是否压缩，默认0表示不压缩，1表示用gzip压缩，2表示用snappy压缩。压缩后消息中会有头来指明消息压缩类型，故在消费者端消息解压是透明的无需指定。
compression.codec=none
  
# 指定序列化处理类(mafka client API调用说明-->3.序列化约定wiki)，默认为kafka.serializer.DefaultEncoder,即byte[]
serializer.class=com.meituan.mafka.client.codec.MafkaMessageEncoder
# serializer.class=kafka.serializer.DefaultEncoder
# serializer.class=kafka.serializer.StringEncoder
# 如果要压缩消息，这里指定哪些topic要压缩消息，默认empty，表示不压缩。
#compressed.topics=
 
########### request ack ###############
# producer接收消息ack的时机.默认为0. 
# 0: producer不会等待broker发送ack 
# 1: 当leader接收到消息之后发送ack 
# 2: 当所有的follower都同步消息成功后发送ack. 
request.required.acks=0 
# 在向producer发送ack之前,broker允许等待的最大时间 
# 如果超时,broker将会向producer发送一个error ACK.意味着上一次消息因为某种 
# 原因未能成功(比如follower未能同步成功) 
request.timeout.ms=10000
########## end #####################
 
 
# 同步还是异步发送消息，默认“sync”表同步，"async"表异步。异步可以提高发送吞吐量,
# 也意味着消息将会在本地buffer中,并适时批量发送，但是也可能导致丢失未发送过去的消息
producer.type=sync
############## 异步发送 (以下四个异步参数可选) ####################
# 在async模式下,当message被缓存的时间超过此值后,将会批量发送给broker,默认为5000ms
# 此值和batch.num.messages协同工作.
queue.buffering.max.ms = 5000
# 在async模式下,producer端允许buffer的最大消息量
# 无论如何,producer都无法尽快的将消息发送给broker,从而导致消息在producer端大量沉积
# 此时,如果消息的条数达到阀值,将会导致producer端阻塞或者消息被抛弃，默认为10000
queue.buffering.max.messages=20000
# 如果是异步，指定每次批量发送数据量，默认为200
batch.num.messages=500
# 当消息在producer端沉积的条数达到"queue.buffering.max.meesages"后 
# 阻塞一定时间后,队列仍然没有enqueue(producer仍然没有发送出任何消息) 
# 此时producer可以继续阻塞或者将消息抛弃,此timeout值用于控制"阻塞"的时间 
# -1: 无阻塞超时限制,消息不会被抛弃 
# 0:立即清空队列,消息被抛弃 
queue.enqueue.timeout.ms=-1
################ end ###############
 
# 当producer接收到error ACK,或者没有接收到ACK时,允许消息重发的次数 
# 因为broker并没有完整的机制来避免消息重复,所以当网络异常时(比如ACK丢失) 
# 有可能导致broker接收到重复的消息,默认值为3.
message.send.max.retries=3
 
 
# producer刷新topic metada的时间间隔,producer需要知道partition leader的位置,以及当前topic的情况 
# 因此producer需要一个机制来获取最新的metadata,当producer遇到特定错误时,将会立即刷新 
# (比如topic失效,partition丢失,leader失效等),此外也可以通过此参数来配置额外的刷新机制，默认值600000 
topic.metadata.refresh.interval.ms=60000
```

# hbase client超时机制相关的几个参数
> ref: [hbase client访问的超时时间、重试次数、重试间隔时间的配置](http://wangneng-168.iteye.com/blog/2067746)
> ref: [HBase最佳实践－客户端超时机制](http://hbasefly.com/2016/06/11/hbase-client-2/)


```
超时时间、重试次数、重试时间间隔的配置也比较重要，因为默认的配置的值都较大，如果出现hbase集群或者RegionServer以及ZK关掉，则对应用程序是灾难性的，超时和重新等会迅速占满web容器的链接，导致web容器停止服务，关于socket的超时时间，有两种：1：建立连接的超时时间；2：读数据的超时时间。
可以配置如下几个参数：
1. hbase.rpc.timeout：rpc的超时时间，默认60s，不建议修改，避免影响正常的业务，在线上环境刚开始配置的是3秒，运行半天后发现了大量的timeout error，原因是有一个region出现了如下问题阻塞了写操作：“Blocking updates … memstore size 434.3m is >= than blocking 256.0m size”可见不能太低。
2. ipc.socket.timeout：socket建立链接的超时时间，应该小于或者等于rpc的超时时间，默认为20s
3. hbase.client.retries.number：重试次数，默认为14，可配置为3
4. hbase.client.pause：重试的休眠时间，默认为1s，可减少，比如100ms
5. zookeeper.recovery.retry：zk的重试次数，可调整为3次，zk不轻易挂，且如果hbase集群出问题了，每次重试均会对zk进行重试操作，zk的重试总次数是：hbase.client.retries.number * zookeeper.recovery.retry，并且每次重试的休眠时间均会呈2的指数级增长，每次访问hbase均会重试，在一次hbase操作中如果涉及多次zk访问，则如果zk不可用，则会出现很多次的zk重试，非常浪费时间。
6. zookeeper.recovery.retry.intervalmill：zk重试的休眠时间，默认为1s，可减少，比如：200ms
7. hbase.regionserver.lease.period：scan查询时每次与server交互的超时时间，默认为60s，可不调整。
 
RPC的重试间隔策略：
public static long getPauseTime(final long pause, final int tries) {
int ntries = tries;
// RETRY_BACKOFF[] = { 1, 1, 1, 2, 2, 4, 4, 8, 16, 32, 64 }
    if (ntries >= HConstants.RETRY_BACKOFF.length) {
      ntries = HConstants.RETRY_BACKOFF.length - 1;
    }
    long normalPause = pause * HConstants.RETRY_BACKOFF[ntries];
    long jitter =  (long)(normalPause * RANDOM.nextFloat() * 0.01f); // 1% possible jitter
    return normalPause + jitter;
  }
 
 
ZK的重试间隔策略：
// RetryCounter类
//休眠时间随着重试次数呈2的指数级增长，第一次重试的休眠时间是配置参数的2倍
public void sleepUntilNextRetry() throws InterruptedException {
    int attempts = getAttemptTimes();
    long sleepTime = (long) (retryIntervalMillis * Math.pow(2, attempts));
    timeUnit.sleep(sleepTime);
       }
      
// retriesRemaining，默认值为maxReties，每次重试后减1
       public int getAttemptTimes() {
          return maxRetries-retriesRemaining+1;
       }
```


```
hbase.rpc.timeout

从字面意思就可知道，该参数表示一次RPC请求的超时时间。如果某次RPC时间超过该值，客户端就会主动关闭socket。此时，服务器端就会捕获到如下的异常：


java.io.IOException: Connection reset by peer
        at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
        at sun.nio.ch.IOUtil.read(IOUtil.java:197)
        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:384)
        at org.apache.hadoop.hbase.ipc.RpcServer.channelRead(RpcServer.java:2246)
        at org.apache.hadoop.hbase.ipc.RpcServer$Connection.readAndProcess(RpcServer.java:1496)
....
2016-04-14 21:32:40,173 WARN  [B.DefaultRpcServer.handler=125,queue=5,port=60020] ipc.RpcServer: RpcServer.respondercallId: 7540 service: ClientService methodName: Multi size: 100.2 K connection: 10.160.247.139:56031: output error
2016-04-14 21:32:40,173 WARN  [B.DefaultRpcServer.handler=125,queue=5,port=60020] ipc.RpcServer: B.DefaultRpcServer.handler=125,queue=5,port=60020: caught a ClosedChannelException, this means that the server was processing a request but the client went away. The error message was: null
上述异常经常发生在大量高并发读写业务或者服务器端发生了比较严重的Full GC等场景下，导致某些请求无法得到及时处理，超过了时间间隔。该值默认大小为60000ms，即1min。





hbase.client.operation.timeout

该参数表示HBase客户端发起一次数据操作直至得到响应之间总的超时时间，数据操作类型包括get、append、increment、delete、put等。很显然，hbase.rpc.timeout表示一次RPC的超时时间，而hbase.client.operation.timeout则表示一次操作的超时时间，有可能包含多个RPC请求。举个例子说明，比如一次Put请求，客户端首先会将请求封装为一个caller对象，该对象发送RPC请求到服务器，假如此时因为服务器端正好发生了严重的Full GC，导致这次RPC时间超时引起SocketTimeoutException，对应的就是hbase.rpc.timeout。那假如caller对象发送RPC请求之后刚好发生网络抖动，进而抛出网络异常，HBase客户端就会进行重试，重试多次之后如果总操作时间超时引起SocketTimeoutException，对应的就是hbase.client.operation.timeout。




hbase.client.scanner.timeout.period

看到这里为止，很多细心的童鞋都会发现，hbase.client.operation.timeout参数规定的超时基本涉及到了HBase所有的数据操作，唯独没有scan操作。然而scan操作却是最有可能发生超时的，也因此是用户最为关心的。HBase当然考虑到了这点，并提供了一个单独的超时参数进行设置：hbase.client.scanner.timeout.period。这个参数理解起来稍微有点复杂，需要对scan操作本身有比较全面的理解，这可能也是很多业务用户并不了解的地方。

首先，我们来看一个最简单的scan操作示例：


public static void scan() {
   HTable table=(HTable) getHTablePool().getTable("tb_stu");  
   Scan scan=new Scan(); 
   scan.setMaxResultSize(10000); 
   scan.setCacheing(500);
   ResultScanner rs = table.getScanner(scan);
   for (Result r : rs) {
      for (KeyValue kv : r.raw()) {
          System.out.println(String.format("row:%s, family:%s, qualifier:%s, qualifiervalue:%s,   timestamp:%s.”,
                  Bytes.toString(kv.getRow()),
                  Bytes.toString(kv.getFamily()),  
                  Bytes.toString(kv.getQualifier()),
                  Bytes.toString(kv.getValue()),
                  kv.getTimestamp()));
      ｝
   ｝
}

很多人都会误认为一次scan操作就是一次RPC请求，实际上，一次请求大量数据的scan操作可能会导致多个很严重的后果：服务器端可能因为大量io操作导致io利用率很高，影响其他正常业务请求；大量数据传输会导致网络带宽等系统资源被大量占用；客户端也可能因为内存无法缓存这些数据导致OOM。基于此，HBase会将一次大的scan操作根据设置条件拆分为多个RPC请求，每次只返回规定数量的结果。上述代码中foreach(Result r ：rs)语句实际上等价于Result r = rs.next()，每执行一次next()操作就会调用客户端发送一次RPC请求，参数hbase.client.scanner.timeout.period就用来表示这么一次RPC请求的超时时间，默认为60000ms，一旦请求超时，就会抛出SocketTimeoutException异常。
```

# hbase scan拆分成多次rpc请求
ref: [HBase最佳实践－客户端超时机制](http://hbasefly.com/2016/06/11/hbase-client-2/)

```
一次大的scan操作会被拆分为多个RPC请求，那到底会拆分为多少个呢？

一次scan请求的RPC次数主要和两个因素相关，一个是本次scan的待检索条数，另一个是单次RPC请求的数据条数，很显然，两者的比值就是RPC请求次数。

一次scan的待检索条数由用户设置的条件决定，比如用户想一次获取某个用户最近一个月的所有操作信息，这些信息总和为10w条，那一次scan总扫瞄条数就是10w条。为了防止一次scan操作请求的数据量太大，额外提供了参数maxResultSize对总检索结果大小进行限制，该参数表示一次scan最多可以请求的数据量大小，默认为-1，表示无限制。


单次RPC请求的数据条数由参数caching设定，默认为100条。因为每次RPC请求获取到数据都会缓存到客户端，因此该值如果设置过大，可能会因为一次获取到的数据量太大导致客户端内存oom；而如果设置太小会导致一次大scan进行太多次RPC，网络成本高。
```

# hbase租约机制和rs报错里的leaseException
ref: [HBase最佳实践－客户端超时机制](http://hbasefly.com/2016/06/11/hbase-client-2/)

```
看到leaseException就会想到租约机制，的确，HBase内部在一次完整的scan操作中引入了租约机制。为什么需要租约机制？这和整个scan操作流程有莫大的关系，上文讲到，一次完整的scan通常会被拆分为多个RPC请求，实际实现中，RegionServer接收到第一次RPC请求之后，会为该scan操作生成一个全局唯一的id，称为scanId。除此之外，RegionServer还会进行大量的准备工作，构建整个scan体系，构造需要用到的所有对象，后续的RPC请求只需要携带相同的scanId作为标示就可以直接利用这些已经构建好的资源进行检索。也就是说，在整个scan过程中，客户端其实都占用着服务器端的资源，此时如果此客户端意外宕机，是否就意味着这些资源永远都不能得到释放呢？租约机制就是为了解决这个问题。RegionServer接收到第一次RPC之后，除了生成全局唯一的scanId之外还会生成一个携带有超时时间的lease，超时时间可以通过参数hbase.regionserver.lease.period配置，一旦在超时时间内后续RPC请求没有到来（比如客户端处理太慢），RegionServer就认为客户端出现异常，此时会将该lease销毁并将整个scan所持有的资源全部释放，客户端在处理完成之后再发后续的RPC过来，检查到对应的lease已经不存在，就会抛出如下leaseExcption：


org.apache.hadoop.hbase.regionserver.LeaseException: lease '-8841369309248784313’ does not exist  
      at org.apache.hadoop.hbase.regionserver.Leases.removeLease(Leases.java:230)  
      at org.apache.hadoop.hbase.regionserver.HRegionServer.next(HRegionServer.java:1847)  
      at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)  
      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)  
      at java.lang.reflect.Method.invoke(Method.java:597)  
      at org.apache.hadoop.hbase.ipc.HBaseRPC$Server.call(HBaseRPC.java:570)
      at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.java:1039) 
```

# 几篇关于《Elasticsearch on Azure Guidance》的文档
ref： [Elasticsearch on Azure Guidance](https://docs.microsoft.com/en-us/azure/guidance/guidance-elasticsearch)

local也有，在[resource](resource)下，就不一一列出了。

# login shell vs non-login shell

ref: [Difference between Login shell and Non login shell](http://howtolamp.com/articles/difference-between-login-and-non-login-shell/)

```

Here we will learn the difference between a Login shell and Non login shell.
The shell program, for example Bash, uses a collection of startup scripts to create an environment. Each script has a specific use and affects the login environment differently. Every subsequent script executed can override the values assigned by previous scripts.

Startup is configured differently for Login shells and Non login shells.
1) Login shells
2) Non login shells

 

1) Login shells
A Login shell is started after a successful login, using /bin/login, by reading the /etc/passwd file. Login shell is the first process that executes under our user ID when we log in to a session. The login process tells the shell to behave as a login shell with a convention: passing argument 0, which is normally the name of the shell executable, with a “-” character prepended. For example, for Bash shell it will be -bash.

When Bash is invoked as a Login shell;
→Login process calls /etc/profile
→/etc/profile calls the scripts in /etc/profile.d/
→Login process calls ~/.bash_profile
→~/.bash_profile calls ~/.bashrc
→~/.bashrc calls /etc/bashrc

Login shells include the following.
• Shells created by explicitly telling to login.
examples: # su - | # su -l | # su --login | # su USERNAME - | # su -l USERNAME | # su --login USERNAME | # sudo -i
• Shells created at login, including X login.

A Login shell can be recognized by the following procedure.
Execute the below command in shell.

# echo $0
If the output is the name of our shell, prepended by a dash, then it is a login shell.
For example -bash, -su etc.


 

2) Non login shells
A Non login shell is started by a program without a login. In this case, the program just passes the name of the shell executable. For example, for a Bash shell it will be simply bash.

When bash is invoked as a Non login shell;
→Non-login process(shell) calls ~/.bashrc
→~/.bashrc calls /etc/bashrc
→/etc/bashrc calls the scripts in /etc/profile.d/

Non login shells include the following.
• Shells created using the below command syntax.
examples: # su | # su USERNAME
• Graphical terminals
• Executed scripts
• Any other bash instances

A Non login shell can be recognized by the following procedure.
Execute the below command in shell.

# echo $0
If the output is the name of our shell, does not prepend by a dash, then it is a Non login shell.
For example bash, su etc.

```


比如 `USER` 这个环境变量，有些程序/服务依赖这个，可能需要在crontab脚本里做类似 `export USER=hadoop && ./startup.sh` 的事情

# 踩坑： flume + netty - 丢失pipeline里最后一个的问题

## 背景
1. 自己写的flume source用netty5
2. channel pipeline里两个channelhandler： 一个解析消息，一个处理消息（丢到q里）
```java
ch.pipeline().addLast(new LogStreamEventDecoder(agentCounter), new LogStreamServerHandler(q));
```

## 问题描述
1. 在本地跑的ok，测试环境一直报错
2. 报错情况定位到能解析出消息，但q consumer一直没收到
3. 报错内容如下：
```
23 Dec 2016 17:47:07,920 DEBUG [nioEventLoopGroup-3-1] (io.netty.util.internal.logging.Slf4JLogger.debug:76)  - Discarded inbound message [Event headers = {}, body.length = 1717 ] that reached at the tail of the pipeline. Please check your pipeline configuration.
```

## 分析
看着，好像是第二个handler没生效（丢了？），但不明白为什么。

... 考虑包版本问题，看了下，果然是只有`lib/netty-3.9.4.Final.jar`而之前可以run的`lib/netty-3.5.12.Final.jar  lib/netty-all-5.0.0.Alpha2.jar`。

把netty5的包丢到userlib里... 还是不行

把netty5的包移到lib里... ok

## 结论
1. netty5的api跟3都不一样，少包还不报错也是醉了
2. lib/userlib这种东西，不熟悉这套的真是坑

...

