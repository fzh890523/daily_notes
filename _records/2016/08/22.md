
# Valgrind 检测 so的内存泄露 - 不可以
> ref: [VALGRIND: How to use valgrind for “.so” library?](http://stackoverflow.com/questions/20321753/valgrind-how-to-use-valgrind-for-so-library)

```
Not directly. Library does not have an entry point where to start executing it, and valgrind only checks code that is actually executing.

Still, if you want to test a library with valgrind, there is a simple way. Just write a test program, which uses the library in the way that tests the parts and features of library you want tested. Then valgrind that.

It is probably better to write several small test programs to test different features and use patterns, instead if one big one which tries to test everything in one execution (easier to isolate any problem valgrind finds, faster to run).
```

没有执行入口... 不可以

# python async/await 初探

```python
import time
import asyncio

async def do_sth():
    print("before: %d" % int(time.time()))
    await asyncio.sleep(1)
    # await time.sleep(1) 的话，报错 None 不能await。 也即这里await其实会返回一个coroutine对象。 同时time.sleep(1)会阻塞loop
    print("after: %d" % int(time.time()))

loop = asyncio.get_event_loop()
loop.run_until_complete(do_sth())

# 隔了段时间

asyncio.ensure_future(do_sth())
loop.run_forever()
```

output:
```
before: 1471832634
after: 1471832635
before: 1471834569
after: 1471834570
# 然后hang住了
```

```python
In [2]: loop = asyncio.get_event_loop()

In [3]: loop1 = asyncio.get_event_loop()

In [4]: id(loop)
Out[4]: 71205944

In [5]: id(loop1)
Out[5]: 71205944

In [6]: id(asyncio.new_event_loop())
Out[6]: 71288704

In [7]: id(asyncio.new_event_loop())
Out[7]: 71238208
```

```python
In [8]: loop.run
loop.run_forever        loop.run_in_executor    loop.run_until_complete
```

* 跟tornado的设计比较类似，有一个main loop，直接get_event_loop的话取到的是这（同一）个； 同时也资词new_event_loop，顾名思义，每次肯定不同啦
* loop本身并没有执行环境（线程），所以要么在当前线程中执行（run_util_complete/run_forever），要么在executor中执行

## 概念

### await
```
Suspend the execution of coroutine on an awaitable object. Can only be used inside a coroutine function.

await_expr ::=  "await" primary
```

```
awaitable
An object that can be used in an await expression. Can be a coroutine or an object with an __await__() method. See also PEP 492.
```

如果说只能在一个coroutine里await另外一个的话，好奇event loop里是怎么处理的。


### task
**官方文档词条解释**
```
class asyncio.Task(coro, *, loop=None)¶
Schedule the execution of a coroutine: wrap it in a future. A task is a subclass of Future.

A task is responsible for executing a coroutine object in an event loop. If the wrapped coroutine yields from a future, the task suspends the execution of the wrapped coroutine and waits for the completition of the future. When the future is done, the execution of the wrapped coroutine restarts with the result or the exception of the future.

Event loops use cooperative scheduling: an event loop only runs one task at a time. Other tasks may run in parallel if other event loops are running in different threads. While a task waits for the completion of a future, the event loop executes a new task.

The cancellation of a task is different from the cancelation of a future. Calling cancel() will throw a CancelledError to the wrapped coroutine. cancelled() only returns True if the wrapped coroutine did not catch the CancelledError exception, or raised a CancelledError exception.

If a pending task is destroyed, the execution of its wrapped coroutine did not complete. It is probably a bug and a warning is logged: see Pending task destroyed.

Don’t directly create Task instances: use the ensure_future() function or the AbstractEventLoop.create_task() method.

This class is not thread safe.
```

> Future的子类（意味着作用也是封装callable的异步执行）。
> 用于调度coroutine的执行。 

```python
import asyncio

async def slow_operation():
    await asyncio.sleep(1)
    return 'Future is done!'

def got_result(future):
    print(future.result())

    # We have result, so let's stop
    loop.stop()

loop = asyncio.get_event_loop()
task = loop.create_task(slow_operation())
task.add_done_callback(got_result)

# We run forever
loop.run_forever()
```

```python
import asyncio

@asyncio.coroutine
def factorial(name, number):
    f = 1
    for i in range(2, number+1):
        print("Task %s: Compute factorial(%s)..." % (name, i))
        yield from asyncio.sleep(1)
        f *= i
    print("Task %s: factorial(%s) = %s" % (name, number, f))

loop = asyncio.get_event_loop()
tasks = [
    asyncio.ensure_future(factorial("A", 2)),
    asyncio.ensure_future(factorial("B", 3)),
    asyncio.ensure_future(factorial("C", 4))]
loop.run_until_complete(asyncio.gather(*tasks))
loop.close()
```

### future
**官方文档词条解释**
```
class asyncio.Future(*, loop=None)
This class is almost compatible with concurrent.futures.Future.

Differences:

result() and exception() do not take a timeout argument and raise an exception when the future isn’t done yet.
Callbacks registered with add_done_callback() are always called via the event loop’s call_soon_threadsafe().
This class is not compatible with the wait() and as_completed() functions in the concurrent.futures package.
This class is not thread safe.


class concurrent.futures.Future
Encapsulates the asynchronous execution of a callable. Future instances are created by Executor.submit() and should not be created directly except for testing.
```

> 封装了callable的异步执行


```
A future is like the Promise objects from Javascript. It is like a place holder for a value that will be materialized in the future. In the above mentioned case, while waiting on network I/O, a function can give us a container, a promise that it will fill the container with the value when the operation completes. We hold on to the future object and when it's fulfilled, we can call a method on it to retrieve the actual result.

Direct Answer: You don't need ensure_future if you don't need the results. They are good if you need the results or retrieve exceptions occured.
```

* 多future一起wait
```python
from asyncio import get_event_loop, ensure_future, wait

futures = []
for i in range(5):
    futures.append(ensure_future(foo(i)))

loop = get_event_loop()
loop.run_until_complete(wait(futures))
```
* 获取future的结果
```python
import asyncio

@asyncio.coroutine
def slow_operation(future):
    yield from asyncio.sleep(1)
    future.set_result('Future is done!')

loop = asyncio.get_event_loop()
future = asyncio.Future()
asyncio.ensure_future(slow_operation(future))
loop.run_until_complete(future)
print(future.result())
loop.close()
```


### coroutine
**官方文档词条解释**
```
coroutine
Coroutines is a more generalized form of subroutines. Subroutines are entered at one point and exited at another point. Coroutines can be entered, exited, and resumed at many different points. They can be implemented with the async def statement. See also PEP 492.
```

```
A coroutine is a generator function that can both yield values and accept values from the outside. The benefit of using a coroutine is that we can pause the execution of a function and resume it later. In case of a network operation, it makes sense to pause the execution of a function while we're waiting for the response. We can use the time to run some other functions.
```

官方文档里提到coroutine可以做的事情：
* `result = await future` or `result = yield from future` – suspends the coroutine until the future is done, then returns the future’s result, or raises an exception, which will be propagated. (If the future is cancelled, it will raise a CancelledError exception.) Note that tasks are futures, and everything said about futures also applies to tasks.
* `result = await coroutine` or `result = yield from coroutine` – wait for another coroutine to produce a result (or raise an exception, which will be propagated). The coroutine expression must be a call to another coroutine.
* `return expression` – produce a result to the coroutine that is waiting for this one using await or yield from.
* `raise exception` – raise an exception in the coroutine that is waiting for this one using await or yield from.

> task是future，而future和coroutine都可以await/yield from。 那么，***future和coroutine的关系呢***： **task封装了coroutine的异步执行，而future是更广泛的概念，不仅用于coroutine场合**。

#### coroutine的执行
`c()`并不会启动执行coroutine中的代码，而是`await c()`或者`yield from c()`才会。

时序图如下：
![](pics/python_coroutine_seqence_diagram.png)

#### coroutine的使用原则
基本上，对于阻塞syscall，使用`await coroutine_func()`的方式。对于非阻塞syscall，似乎都可以？（如 time.time() 和 loop.time()）

#### coroutine function
```
coroutine function
A function which returns a coroutine object. A coroutine function may be defined with the async def statement, and may contain await, async for, and async with keywords. These were introduced by PEP 492.
```

注意coroutine和coroutine function的关系/区别。 类似 generator function 和 generator。

## 使用tutorial

### 执行

* loop.call_*
```
call_later is designed to take a callback (meaning a regular function object), not a coroutine. 
```
只能是普通函数，不能是coroutine。

### 提交任务

* loop.create_task
```python
In [28]: loop.create_task(do_sth())  # 返回Task
Out[28]: <Task pending coro=<do_sth() running at <ipython-input-11-753066d72c5b>:1>>
```
* asyncio.ensure_future
<del>也有asyncio.ensure_future，估计就是 asyncio.get_event_loop().ensure_future</del>
```
In [26]: asyncio.ensure_future(do_sth())
Out[26]: <Task pending coro=<do_sth() running at <ipython-input-11-753066d72c5b>:1>>
```
* asyncio.async
代码里提到不建议使用，建议使用asyncio.ensure_future
```python
In [29]: asyncio.async(do_sth())
Out[29]: <Task pending coro=<do_sth() running at <ipython-input-11-753066d72c5b>:1>>
```

#### ensure_future VS create_task

```
asyncio.ensure_future(coro_or_future, *, loop=None)
Schedule the execution of a coroutine object: wrap it in a future. Return a Task object.

If the argument is a Future, it is returned directly.

New in version 3.4.4.

Changed in version 3.5.1: The function accepts any awaitable object.

See also The AbstractEventLoop.create_task() method.
```

```
AbstractEventLoop.create_task(coro)
Schedule the execution of a coroutine object: wrap it in a future. Return a Task object.

Third-party event loops can use their own subclass of Task for interoperability. In this case, the result type is a subclass of Task.

This method was added in Python 3.4.2. Use the async() function to support also older Python versions.

New in version 3.4.2.
```

似乎没啥区别，只是前者用于`ensure`，提供了传入future的兼容。

# yield from小议
之前一直没太明白，看了对应的PEP380的title以后就恍然了。
> ref: [PEP 380 -- Syntax for Delegating to a Subgenerator](http://legacy.python.org/dev/peps/pep-0380/)

**委托给子生成器**

典型的generator
```python
def g1():
    # do sth
    yield f()
    # do sth
```

但如果f本身也是生成器函数呢，如果还是原来那样的话，会把f()得到的生成器给yield回了，不是预期的行为。 需要写成类似如下：
```python
def g1():
    # do sth
    g = f()
    for i in g:
        yield i
    # do sth
```
这样层次多了就很烦了。

新的写法：
```python
def g1():
    yield from f()
```


```python
In [22]: def f():
   ....:     i = 0
   ....:     while i < 3:
   ....:         yield i
   ....:         i += 1
   ....:

In [23]: for i in f():
   ....:     print(i)
   ....:
0
1
2

In [24]: def g1():
   ....:     yield f()
   ....:

In [25]: for i in g1():
   ....:     print(i)
   ....:
<generator object f at 0x00000000046C8A40>

In [26]: def g2():
   ....:     for i in f():
   ....:         yield i
   ....:

In [27]: for i in g2():
   ....:     print(i)
   ....:
0
1
2

In [28]: def g3():
   ....:     yield from f()
   ....:

In [29]: for i in g3():
   ....:     print(i)
   ....:
0
1
2
```

下文写的不错： [Python3中的yield from语法](resource/Python3中的yield from语法 - The Error Log.html)

# python3中的asyncio
参见以上...
以及 [Python3中的asyncio](resource/Python3中的asyncio - The Error Log.html)

# dapper论文翻译 - 中文
> ref: [Dapper，大规模分布式系统的跟踪系统 by bigbully](resource/Dapper，大规模分布式系统的跟踪系统 by bigbully.htm)

