
# 关于es查询多个index

> ref: [Multi-index, Multitype](https://www.elastic.co/guide/en/elasticsearch/guide/current/multi-index-multi-type.html)


有张表从按月分表改为按天分表，在查询上有疑问。
es虽然支持同时查询多个index，但排序的话怎么做呢？
ref的链接里提到，分别向多个...查询数据，但怎么聚合？ 涉及到排序，可不是简单的把取回的多份结果排序然后取前面xx就行了。

## 结论

未决 TODO


# dapper kafka报错：kafka.common.MessageStreamsExistException: ZookeeperConsumerConnector can create message streams at most once

```
2016-11-15 12:51:17,276 ERROR o.s.i.h.LoggingHandler [task-scheduler-5] kafka.common.MessageStreamsExistException: ZookeeperConsumerConnector can create message streams at most once
        at kafka.javaapi.consumer.ZookeeperConsumerConnector.createMessageStreams(ZookeeperConsumerConnector.scala:79)
        at org.springframework.integration.kafka.support.ConsumerConfiguration.createMessageStreamsForTopic(ConsumerConfiguration.java:238)
        at org.springframework.integration.kafka.support.ConsumerConfiguration.createConsumerMessageStreams(ConsumerConfiguration.java:227)
        at org.springframework.integration.kafka.support.ConsumerConfiguration.receive(ConsumerConfiguration.java:99)
        at org.springframework.integration.kafka.support.KafkaConsumerContext.receive(KafkaConsumerContext.java:76)
        at org.springframework.integration.kafka.inbound.KafkaHighLevelConsumerMessageSource.receive(KafkaHighLevelConsumerMessageSource.java:42)
        at org.springframework.integration.endpoint.SourcePollingChannelAdapter.receiveMessage(SourcePollingChannelAdapter.java:209)
        at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:245)
        at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:58)
        at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:190)
        at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:186)
        at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:353)
        at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:55)
        at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
        at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:51)
        at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:344)
        at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
        at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)

```

参考

*   [apache kafka系列之kafka.common.ConsumerRebalanceFailedException异常解决办法](http://blog.csdn.net/lizhitao/article/details/25301387)

## 跟进

> ref: [apache kafka系列之kafka.common.ConsumerRebalanceFailedException异常解决办法](http://blog.csdn.net/lizhitao/article/details/25301387)
> ref: [kafka Documentation](https://kafka.apache.org/08/documentation.html)

```xml
    <int-kafka:zookeeper-connect id="zookeeperConnect"
                                 zk-connect="${kafka.zk}/kafka" zk-connection-timeout="6000"
                                 zk-session-timeout="400000" zk-sync-time="200"/>
```

zookeeper.session.timeout.ms    6000    Zookeeper session timeout. If the server fails to heartbeat to zookeeper within this period of time it is considered dead. If you set this too low the server may be falsely considered dead; if you set it too high it may take too long to recognize a truly dead server.
rebalance.max.retries   4   When a new consumer joins a consumer group the set of consumers attempt to "rebalance" the load to assign partitions to each consumer. If the set of consumers changes while this assignment is taking place the rebalance will fail and retry. This setting controls the maximum number of attempts before giving up.
rebalance.backoff.ms    2000    Backoff time between retries during rebalance.

```
 apache kafka系列之kafka.common.ConsumerRebalanceFailedException异常解决办法
标签： apache kafkaConsumerRebalanceFaiapache kafka系列
2014-05-08 14:02 8236人阅读 评论(0) 收藏 举报
 分类： apache kafka（73）  
版权声明：本文为博主原创文章，未经博主允许不得转载。
kafka.common.ConsumerRebalanceFailedException :log-push-record-consumer-group_mobile-pushremind02.lf.xxx.com-1399456594831-99f15e63 can't rebalance after 3 retries
at kafka.consumer.ZookeeperConsumerConnector$ZKRebalancerListener.syncedRebalance(Unknown Source)
at kafka.consumer.ZookeeperConsumerConnector.kafka$consumer$ZookeeperConsumerConnector$$reinitializeConsumer(Unknown Source)
at kafka.consumer.ZookeeperConsumerConnector.consume(Unknown Source)
at kafka.javaapi.consumer.ZookeeperConsumerConnector.createMessageStreams(Unknown Source)
at com.xxx.mafka.client.consumer.DefaultConsumerProcessor.getKafkaStreams(DefaultConsumerProcessor.java:149)
at com.xxx.mafka.client.consumer.DefaultConsumerProcessor.recvMessage(DefaultConsumerProcessor.java:63)
at com.xxx.service.mobile.push.kafka.MafkaPushRecordConsumer.main(MafkaPushRecordConsumer.java:22)
at com.xxx.service.mobile.push.Bootstrap.main(Bootstrap.Java:34)

出现以上问题原因分析：
同一个消费者组(consumer group)有多个consumer先后启动，就是一个消费者组内有多个consumer同时负载消费多个partition数据.
解决办法：
1.配置zk问题(kafka的consumer配置)
zookeeper.session.timeout.ms=5000
zookeeper.connection.timeout.ms=10000
rebalance.backoff.ms=2000
rebalance.max.retries=10


在使用高级API过程中，一般出现这个问题是zookeeper.sync.time.ms时间间隔配置过短，不排除有其他原因引起，但笔者遇到一般是这个原因。
给大家解释一下原因：一个消费者组中(consumer数量<partitions数量)每当有consumer发送变化，会触发负载均衡。第一件事就是释放当consumer资源，无则免之，调用ConsumerFetcherThread关闭并释放当前kafka broker所有连接，释放当前消费的partitons，实际就是删除临时节点(/xxx/consumer/owners/topic-xxx/partitions[0-n]),所有同一个consumer group内所有consumer通过计算获取本consumer要消费的partitions，然后本consumer注册相应临时节点卡位，代表我拥有该partition的消费所有权，其他consumer不能使用。

如果大家理解上面解释，下面就更容易了，当consumer调用Rebalance时，它是按照时间间隔和最大次数采取失败重试原则，每当获取partitions失败后会重试获取。举个例子，假如某个公司有个会议，B部门在某个时间段预订该会议室，但是时间到了去会议室看时，发现A部门还在使用。这时B部门只有等待了，每隔一段时间去询问一下。如果时间过于频繁，则会议室一直会处于占用状态，如果时间间隔设置长点，可能去个2次，A部门就让出来了。

同理，当新consumer加入重新触发rebalance时，已有(old)的consumer会重新计算并释放占用partitions，但是会消耗一定处理时间，此时新(new)consumer去抢占该partitions很有可能就会失败。我们假设设置足够old consumer释放资源的时间，就不会出现这个问题。

官方解释：
consumer rebalancing fails (you will see ConsumerRebalanceFailedException): This is due to conflicts when two consumers are trying to own the same topic partition. The log will show you what caused the conflict (search for "conflict in ").
If your consumer subscribes to many topics and your ZK server is busy, this could be caused by consumers not having enough time to see a consistent view of all consumers in the same group. If this is the case, try Increasing rebalance.max.retries and rebalance.backoff.ms.
Another reason could be that one of the consumers is hard killed. Other consumers during rebalancing won't realize that consumer is gone after zookeeper.session.timeout.ms time. In the case, make sure that rebalance.max.retries * rebalance.backoff.ms > zookeeper.session.timeout.ms.

rebalance.backoff.ms时间设置过短就会导致old consumer还没有来得及释放资源，new consumer重试失败多次到达阀值就退出了。

确保rebalance.max.retries * rebalance.backoff.ms > zookeeper.session.timeout.ms

kafka zk节点存储，请参考：kafka在zookeeper中存储结构


参考资料：https://cwiki.apache.org/confluence/display/KAFKA/FAQ
```


## 结论
去掉zk session timeout的过大的配置（使用默认的6000）后，不再出现。
`rebalance.max.retries * rebalance.backoff.ms > zookeeper.session.timeout.ms`
默认值： `4 * 2000 > 6000`

## 后续
换了新的kafka（zk）集群以后又出现了。
见work record的 2016/12/02。


