
# 使用端口较多的服务端程序可能遇到address in use问题
> ref: 《bilitw 启动报错 Address already in use 调查》

## 背景
1. 多个进程bind/listen同一个端口，使用了REUSEADDR和REUSEPORT
2. 间歇性出现“Address already in use”
3. tw服务使用较多的listen端口（-lvs-client）以及更多的local port（-cache server）

## 结论
tw配置listen在值较大（3w）的port范围同时tw使用大量的local port从而干扰了listen port。 并且服务的cache集群越多（每增加一个则增加一个listen port和 worker_num * cache_cluster_node_num个local port），从而表现出`越来越严重`。

# TIME_WAIT状态socket 和 SO_REUSEADDR


## TIME_WAIT对port的影响
如果port上还有TIME_WAIT状态的连接/socket的话，是不会被彻底释放的。 bind时会遇到EADDRINUSE。
而如果该socket是以SO_REUSEADDR打开的话，那么当遇到该情况时，同一用户还是可以用SO_REUSEADDR 打开并bind到该port。

# 小叙SO_REUSEPORT
> ref: SO_REUSEPORT socket选项小结_yonka

## 背景
* 传统模式一： 多线程模型中，一个线程accept，其他线程serve socket。 这样可能导致瓶颈在accept的线程。
* 传统模式二： 多个线程都accept在同一个listening socket。 带来的问题：
    1. 惊群（thundering herd）： 一个请求来，唤醒所有线程而又只能有一个处理其他的又恢复阻塞。
    2. （可能是1的改进，选择性唤醒）唤醒分布不均： 在高负荷情况下，新连接可能分布的很不均匀，导致CPU使用不均。

## 简介

第一个bind到该地址（端口）的socket有该选项的话，那么允许后面的其他listening sockets也带该选项bind到该地址（端口）。
为了避免“劫持”，后面bind的线程，需要EUID和第一个线程一样。
这样就可以同时存在多个bind到该地址（端口）的listening sockets，增加accept的性能。

对TCP和UDP都可以设置该选项，TCP针对new conn，UDP针对packet。


## 好处和不足
### 好处
对唤醒分布不均的改善：
这时多个listening线程是accept在多个（bind到同一个地址/端口的）sockets上，内核会采取一些调度算法来使其均衡（比如采取四元组hash的方式dispatch conn）

### 不足
* 仍然可能分布不均
> 均衡算法局限性： 四元组hash的方式如果数据主要集中在少数client（addr+port）而这些client又正好hash到个别listening socket的话，还是会分布不均（主要对UDP吧？TCP的话一个client不可能一直new conn）
* 实现问题导致当listening sockets数量发生变化时可能丢连接
> 变化可能是 新的加入或者老的终止。
三次握手之后才有稳定映射关系，三次握手期间发生变化的话后面的包（比如最后一个ACK）可能和前面的包（比如SYN）发给不同的listening socket，导致... 



## SO_REUSEPORT的另一个场景
比如： A服务bind到了`0.0.0.0:8080`而B服务希望bind到`192.168.0.1:8080`，那么就必须

# 控制local port段的内核参数： ip_local_port_range
> The /proc/sys/net/ipv4/ip_local_port_range defines the local port range that is used by TCP and UDP traffic to choose the local port. 
> You will see in the parameters of this file two numbers: The first number is the first local port allowed for TCP and UDP traffic on the server, the second is the last local port number. For high-usage systems you may change its default parameters to 32768-61000 -first-last.`

格式是 `${first} ${last}`，只能配置一个段。
有说法是要`/etc/rc.d/init.d/network restart`才生效，但新版linux里似乎提供更多方式。

## 查看
```
sysctl net.ipv4.ip_local_port_range

Sample outputs:

net.ipv4.ip_local_port_range = 32768    61000
```

## 设置
```
echo 1024 65535 > /proc/sys/net/ipv4/ip_local_port_range

# OR

sudo sysctl -w net.ipv4.ip_local_port_range="1024 64000"
```

### 永久（启动后）生效
edit `/etc/sysctl.conf` file

```
# increase system IP port limits
net.ipv4.ip_local_port_range = 1024 65535 
```

# socket client可以先bind后使用
相对少见的做法，因为client一般不介意使用的端口同时也更难保证使用的端口（没有被占用），所以一般都是由系统分配。
但确实也支持自行指定（虽然可能会冲突）。

而bind到0 port则表示由内核分配，一般用于需要指定路由（出口IP/src IP）但不关心src port的情况。

## python示例
```python
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# Let the source address be 192.168.1.21:1234
s.bind(("192.168.1.21", 1234))
s.connect(("www.google.com", 80))
```


```python
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.bind(("192.168.1.21", 0))
s.connect(("www.google.com", 80))
```

## bind + SO_REUSEADDR + connect
这样可以使用TIME_WAIT状态的port。

```python
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
s.bind(("192.168.1.21", 0))
s.connect(("www.google.com", 80))
```


## bind+connect vs connect
```
Unfortunately, connections established with normal connect and with bind before connect don't mix well. Outgoing ports used by one technique can't be reused by another. If you establish 64k connections using connect, bind will fail with EADDRINUSE. And the other way around: when thousands of connections are using bind before connect straight connect might fail with EADDRNOTAVAIL.
```

# linux内核中选择socket client local port的代码
```c
/* Obtain a reference to a local port for the given sock,
 * if snum is zero it means select any available local port.
 */
int inet_csk_get_port(struct sock *sk, unsigned short snum)
{
    struct inet_hashinfo *hashinfo = sk->sk_prot->h.hashinfo;
    struct inet_bind_hashbucket *head;
    struct inet_bind_bucket *tb;
    int ret, attempts = 5;
    struct net *net = sock_net(sk);
    int smallest_size = -1, smallest_rover;
    kuid_t uid = sock_i_uid(sk);

    local_bh_disable();
    if (!snum) {
        int remaining, rover, low, high;

again:
        inet_get_local_port_range(net, &low, &high);
        remaining = (high - low) + 1;
        smallest_rover = rover = net_random() % remaining + low;

        smallest_size = -1;
        do {
            if (inet_is_reserved_local_port(rover))
                goto next_nolock;
            head = &hashinfo->bhash[inet_bhashfn(net, rover,
                    hashinfo->bhash_size)];
            spin_lock(&head->lock);
            inet_bind_bucket_for_each(tb, &head->chain)
                if (net_eq(ib_net(tb), net) && tb->port == rover) {
                    if (((tb->fastreuse > 0 &&
                          sk->sk_reuse &&
                          sk->sk_state != TCP_LISTEN) ||
                         (tb->fastreuseport > 0 &&
                          sk->sk_reuseport &&
                          uid_eq(tb->fastuid, uid))) &&
                        (tb->num_owners < smallest_size || smallest_size == -1)) {
                        smallest_size = tb->num_owners;
                        smallest_rover = rover;
                        if (atomic_read(&hashinfo->bsockets) > (high - low) + 1 &&
                            !inet_csk(sk)->icsk_af_ops->bind_conflict(sk, tb, false)) {
                            snum = smallest_rover;
                            goto tb_found;
                        }
                    }
                    if (!inet_csk(sk)->icsk_af_ops->bind_conflict(sk, tb, false)) {
                        snum = rover;
                        goto tb_found;
                    }
                    goto next;
                }
            break;
        next:
            spin_unlock(&head->lock);
        next_nolock:
            if (++rover > high)
                rover = low;
        } while (--remaining > 0);

        /* Exhausted local port range during search?  It is not
         * possible for us to be holding one of the bind hash
         * locks if this test triggers, because if 'remaining'
         * drops to zero, we broke out of the do/while loop at
         * the top level, not from the 'break;' statement.
         */
        ret = 1;
        if (remaining <= 0) {
            if (smallest_size != -1) {
                snum = smallest_rover;
                goto have_snum;
            }
            goto fail;
        }
        /* OK, here is the one we will use.  HEAD is
         * non-NULL and we hold it's mutex.
         */
        snum = rover;
    } else {
have_snum:
        head = &hashinfo->bhash[inet_bhashfn(net, snum,
                hashinfo->bhash_size)];
        spin_lock(&head->lock);
        inet_bind_bucket_for_each(tb, &head->chain)
            if (net_eq(ib_net(tb), net) && tb->port == snum)
                goto tb_found;
    }
    tb = NULL;
    goto tb_not_found;
tb_found:
    if (!hlist_empty(&tb->owners)) {
        if (sk->sk_reuse == SK_FORCE_REUSE)
            goto success;

        if (((tb->fastreuse > 0 &&
              sk->sk_reuse && sk->sk_state != TCP_LISTEN) ||
             (tb->fastreuseport > 0 &&
              sk->sk_reuseport && uid_eq(tb->fastuid, uid))) &&
            smallest_size == -1) {
            goto success;
        } else {
            ret = 1;
            if (inet_csk(sk)->icsk_af_ops->bind_conflict(sk, tb, true)) {
                if (((sk->sk_reuse && sk->sk_state != TCP_LISTEN) ||
                     (tb->fastreuseport > 0 &&
                      sk->sk_reuseport && uid_eq(tb->fastuid, uid))) &&
                    smallest_size != -1 && --attempts >= 0) {
                    spin_unlock(&head->lock);
                    goto again;
                }

                goto fail_unlock;
            }
        }
    }
tb_not_found:
    ret = 1;
    if (!tb && (tb = inet_bind_bucket_create(hashinfo->bind_bucket_cachep,
                    net, head, snum)) == NULL)
        goto fail_unlock;
    if (hlist_empty(&tb->owners)) {
        if (sk->sk_reuse && sk->sk_state != TCP_LISTEN)
            tb->fastreuse = 1;
        else
            tb->fastreuse = 0;
        if (sk->sk_reuseport) {
            tb->fastreuseport = 1;
            tb->fastuid = uid;
        } else
            tb->fastreuseport = 0;
    } else {
        if (tb->fastreuse &&
            (!sk->sk_reuse || sk->sk_state == TCP_LISTEN))
            tb->fastreuse = 0;
        if (tb->fastreuseport &&
            (!sk->sk_reuseport || !uid_eq(tb->fastuid, uid)))
            tb->fastreuseport = 0;
    }
success:
    if (!inet_csk(sk)->icsk_bind_hash)
        inet_bind_hash(sk, tb, snum);
    WARN_ON(inet_csk(sk)->icsk_bind_hash != tb);
    ret = 0;

fail_unlock:
    spin_unlock(&head->lock);
fail:
    local_bh_enable();
    return ret;
}
EXPORT_SYMBOL_GPL(inet_csk_get_port);

int inet_csk_bind_conflict(const struct sock *sk,
               const struct inet_bind_bucket *tb, bool relax)
{
    struct sock *sk2;
    int reuse = sk->sk_reuse;
    int reuseport = sk->sk_reuseport;
    kuid_t uid = sock_i_uid((struct sock *)sk);

    /*
     * Unlike other sk lookup places we do not check
     * for sk_net here, since _all_ the socks listed
     * in tb->owners list belong to the same net - the
     * one this bucket belongs to.
     */

    sk_for_each_bound(sk2, &tb->owners) {
        if (sk != sk2 &&
            !inet_v6_ipv6only(sk2) &&
            (!sk->sk_bound_dev_if ||
             !sk2->sk_bound_dev_if ||
             sk->sk_bound_dev_if == sk2->sk_bound_dev_if)) {
            if ((!reuse || !sk2->sk_reuse ||
                sk2->sk_state == TCP_LISTEN) &&
                (!reuseport || !sk2->sk_reuseport ||
                (sk2->sk_state != TCP_TIME_WAIT &&
                 !uid_eq(uid, sock_i_uid(sk2))))) {

                if (!sk2->sk_rcv_saddr || !sk->sk_rcv_saddr ||
                    sk2->sk_rcv_saddr == sk->sk_rcv_saddr)
                    break;
            }
            if (!relax && reuse && sk2->sk_reuse &&
                sk2->sk_state != TCP_LISTEN) {

                if (!sk2->sk_rcv_saddr || !sk->sk_rcv_saddr ||
                    sk2->sk_rcv_saddr == sk->sk_rcv_saddr)
                    break;
            }
        }
    }
    return sk2 != NULL;
}
EXPORT_SYMBOL_GPL(inet_csk_bind_conflict);
```


# 修改HBase表的TTL
1. disable 'test_tbl'
2. alter 'test_tbl', NAME=>'f1', TTL=>29600
> 注意： TTL是配置在CF上的
> 也可以 alter 'test_tbl', {NAME=>'f1', TTL=>29600}
3. enable 'test_tbl'

# java服务执行“收尾”操作
如果是简单的收尾，可以：
```java
Runtime.getRuntime().addShutdownHook(new Thread() {
    @Override
    public void run() {
        collector.stop();
    }
});
```
但注意，该操作是在JVM销毁前进行的（也即在**最后的最后**执行），各个线程都被干掉了，如果还依赖业务线程配合收尾的话，则不能使用该方式。 可以选用signal handler。
```java
SignalHandler handler = signal -> {
    collector.stop();
};
Signal.handle(new Signal("INT"), handler);
Signal.handle(new Signal("TERM"), handler);
```